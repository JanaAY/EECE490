{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VD64cqFHMqb7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Base directory ===\n",
        "base_dir = \"/content/drive/MyDrive/EECE 490 Project/Aptos\"\n",
        "input_train_dir = os.path.join(base_dir, \"train_images\")\n",
        "input_test_dir = os.path.join(base_dir, \"test_images\")\n",
        "output_train_dir = os.path.join(base_dir, \"train_images_jpeg\")\n",
        "output_test_dir = os.path.join(base_dir, \"test_images_jpeg\")\n",
        "\n",
        "# === Create output folders ===\n",
        "os.makedirs(output_train_dir, exist_ok=True)\n",
        "os.makedirs(output_test_dir, exist_ok=True)\n",
        "\n",
        "# === Conversion function ===\n",
        "def convert_png_to_jpeg(input_dir, output_dir):\n",
        "    files = [f for f in os.listdir(input_dir) if f.lower().endswith(\".png\")]\n",
        "    for fname in tqdm(files, desc=f\"Converting {os.path.basename(input_dir)}\"):\n",
        "        img_path = os.path.join(input_dir, fname)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        if img is not None:\n",
        "            new_name = os.path.splitext(fname)[0] + \".jpeg\"\n",
        "            save_path = os.path.join(output_dir, new_name)\n",
        "            cv2.imwrite(save_path, img)\n",
        "\n",
        "# === Convert both sets ===\n",
        "convert_png_to_jpeg(input_train_dir, output_train_dir)\n",
        "convert_png_to_jpeg(input_test_dir, output_test_dir)\n",
        "\n",
        "print(\"âœ… Conversion complete. All .png images saved as .jpeg in new folders.\")\n"
      ],
      "metadata": {
        "id": "uklvchv0MuKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# === Base path ===\n",
        "base_dir = \"/content/drive/MyDrive/EECE 490 Project/Aptos\"\n",
        "train_path = os.path.join(base_dir, \"train.csv\")\n",
        "test_path = os.path.join(base_dir, \"test.csv\")\n",
        "\n",
        "# === Load CSV files ===\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "# === Count DR level distribution ===\n",
        "train_dist = train_df['diagnosis'].value_counts().sort_index()\n",
        "\n",
        "# === Display counts ===\n",
        "print(\"ðŸ“Š DR Level Distribution in train.csv:\")\n",
        "for level, count in train_dist.items():\n",
        "    print(f\"  Level {level}: {count} images\")\n"
      ],
      "metadata": {
        "id": "oj-EH9R3QMgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Imports ===\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# === Black Border Remover ===\n",
        "def remove_black_border(img, threshold=5):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours:\n",
        "        return img\n",
        "    x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
        "    return img[y:y+h, x:x+w]\n",
        "\n",
        "# === Auto Flip if Left Eye ===\n",
        "def auto_flip_if_left_eye(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    h, w = gray.shape\n",
        "    left = np.mean(gray[:, :w//2])\n",
        "    right = np.mean(gray[:, w//2:])\n",
        "    if right > left:\n",
        "        return cv2.flip(img, 1)  # horizontal flip\n",
        "    return img\n",
        "\n",
        "# === Full Preprocessing Pipeline (Resizing moved to end) ===\n",
        "def preprocess_image_full(img, target_size=(512, 512), blur_thresh=20.0, brightness_thresh=25):\n",
        "    try:\n",
        "        if img is None or len(img.shape) != 3 or img.shape[2] != 3:\n",
        "            return None\n",
        "\n",
        "        # Blur and brightness checks\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        if cv2.Laplacian(gray, cv2.CV_64F).var() < blur_thresh:\n",
        "            return None\n",
        "        if np.mean(gray) < brightness_thresh:\n",
        "            return None\n",
        "\n",
        "        # Remove black borders\n",
        "        img = remove_black_border(img)\n",
        "\n",
        "        # Auto flip if left eye\n",
        "        img = auto_flip_if_left_eye(img)\n",
        "\n",
        "        # CLAHE enhancement\n",
        "        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "        l = clahe.apply(l)\n",
        "        img = cv2.cvtColor(cv2.merge((l, a, b)), cv2.COLOR_LAB2BGR)\n",
        "\n",
        "        # Glare detection\n",
        "        glare_mask = cv2.inRange(img, (240, 240, 240), (255, 255, 255))\n",
        "        contours, _ = cv2.findContours(glare_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if any(cv2.contourArea(c) > 500 for c in contours):\n",
        "            return None\n",
        "\n",
        "        # Text/annotation filter\n",
        "        mask_text = cv2.inRange(img, (220, 220, 220), (255, 255, 255))\n",
        "        if cv2.countNonZero(mask_text) > 3000:\n",
        "            return None\n",
        "\n",
        "        # Dark region filter\n",
        "        if np.mean(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) > 10) < 0.2:\n",
        "            return None\n",
        "\n",
        "        # âœ… Resize (critical fix)\n",
        "        img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        # âœ… Validate shape before return\n",
        "        if img.shape != (512, 512, 3):\n",
        "            raise ValueError(f\"Resized image has invalid shape: {img.shape}\")\n",
        "\n",
        "        # Normalize to [-1, 1]\n",
        "        return img.astype(np.float32) / 127.5 - 1.0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Exception during processing: {e}\")\n",
        "        return None\n",
        "\n",
        "# === Set Input/Output Folders ===\n",
        "input_folder = \"/content/drive/MyDrive/EECE 490 Project/Aptos/train_images_jpeg\"\n",
        "output_folder = \"/content/drive/MyDrive/EECE 490 Project/Aptos/train_images_cleaned\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# === Run Preprocessing ===\n",
        "skipped = []\n",
        "image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.jpeg', '.jpg', '.png'))]\n",
        "sample_images = []\n",
        "\n",
        "for fname in tqdm(image_files):\n",
        "    in_path = os.path.join(input_folder, fname)\n",
        "    out_path = os.path.join(output_folder, fname)\n",
        "\n",
        "    img = cv2.imread(in_path)\n",
        "    if img is None:\n",
        "        skipped.append(fname)\n",
        "        continue\n",
        "\n",
        "    processed = preprocess_image_full(img)\n",
        "    if processed is None:\n",
        "        skipped.append(fname)\n",
        "        continue\n",
        "    if processed.shape != (512, 512, 3):\n",
        "        print(f\"âš ï¸ Unexpected size in {fname}: {processed.shape}\")\n",
        "        skipped.append(fname)\n",
        "        continue\n",
        "\n",
        "    out_img = ((processed + 1.0) * 127.5).astype(np.uint8)\n",
        "    cv2.imwrite(out_path, out_img)\n",
        "\n",
        "    if len(sample_images) < 10 and random.random() < 0.1:\n",
        "        sample_images.append(cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "# === Show Random Previews ===\n",
        "if sample_images:\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    for i, img in enumerate(sample_images):\n",
        "        plt.subplot(1, len(sample_images), i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"âš ï¸ No sample images to display.\")\n",
        "\n",
        "print(f\"\\nâœ… Done! Preprocessed images saved to: {output_folder} | Skipped {len(skipped)} bad images.\")\n"
      ],
      "metadata": {
        "id": "ylhtnQ2oFz8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# === Folder containing images ===\n",
        "folder_path = \"/content/drive/MyDrive/EECE 490 Project/Aptos/train_images_cleaned\"\n",
        "\n",
        "# === Loop through all files and check dimensions ===\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"âŒ Could not read {filename}\")\n",
        "            continue\n",
        "\n",
        "        h, w = img.shape[:2]\n",
        "        if h != 512 or w != 512:\n",
        "            print(f\"âš ï¸ {filename} has size {w}x{h}\")\n"
      ],
      "metadata": {
        "id": "IdeZyw5BRWSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_images = [f for f in os.listdir(\"/content/drive/MyDrive/EECE 490 Project/Aptos/train_images_cleaned\") if f.lower().endswith(('.jpeg', '.jpg', '.png'))]\n",
        "print(f\"ðŸ§¼ Number of cleaned images: {len(cleaned_images)}\")\n"
      ],
      "metadata": {
        "id": "8Zn6Ky2eRkBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# === Load the combined CSV file ===\n",
        "csv_path = \"/content/drive/MyDrive/EECE 490 Project/Aptos/train.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# === Define where your JPEG images are stored ===\n",
        "output_folder = \"/content/drive/MyDrive/EECE 490 Project/Aptos/train_images_cleaned\"\n",
        "kept_images = set(os.listdir(output_folder))\n",
        "\n",
        "# === Filter rows based on available images ===\n",
        "df_filtered = df[df['id_code'].apply(lambda x: f\"{x}.jpeg\" in kept_images)]\n",
        "\n",
        "# === Count and display label distribution ===\n",
        "label_counts = df_filtered['diagnosis'].value_counts().sort_index()\n",
        "count_0 = label_counts.get(0, 0)\n",
        "count_1 = label_counts.get(1, 0)\n",
        "count_2 = label_counts.get(2, 0)\n",
        "count_3 = label_counts.get(3, 0)\n",
        "count_4 = label_counts.get(4, 0)\n",
        "\n",
        "print(f\"âœ… Remaining samples:\\n  No_DR (0): {count_0}\\n  DR (1): {count_1}\\n  DR (2): {count_2}\\n  DR (3): {count_3}\\n  DR (4): {count_4}\")\n",
        "\n",
        "# === Save the filtered DataFrame to a new CSV file ===\n",
        "output_csv_path = \"/content/drive/MyDrive/EECE 490 Project/Aptos/train_cleaned.csv\"\n",
        "df_filtered.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"\\nðŸ“ Filtered CSV file saved to: {output_csv_path}\")\n"
      ],
      "metadata": {
        "id": "vsnSi8ygRxPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "# === Paths ===\n",
        "base_dir = \"/content/drive/MyDrive/EECE 490 Project/Aptos\"\n",
        "input_csv = os.path.join(base_dir, \"train_cleaned.csv\")\n",
        "input_images_folder = os.path.join(base_dir, \"train_images_cleaned\")\n",
        "output_csv = os.path.join(base_dir, \"train_unbalanced_split.csv\")\n",
        "output_split_folder = os.path.join(base_dir, \"Unbalanced_Split_train\")\n",
        "no_dr_folder = os.path.join(output_split_folder, \"NoDR\")\n",
        "dr_folder = os.path.join(output_split_folder, \"DR\")\n",
        "\n",
        "# === Step 1: Load CSV and add binary_level column ===\n",
        "df = pd.read_csv(input_csv)\n",
        "df[\"binary_level\"] = df[\"diagnosis\"].apply(lambda x: 0 if x == 0 else 1)\n",
        "\n",
        "# === Step 2: Save new CSV file ===\n",
        "df.to_csv(output_csv, index=False)\n",
        "print(f\"âœ… New CSV file saved to: {output_csv}\")\n",
        "\n",
        "# === Step 3: Create output folders ===\n",
        "os.makedirs(no_dr_folder, exist_ok=True)\n",
        "os.makedirs(dr_folder, exist_ok=True)\n",
        "\n",
        "# === Step 4: Copy images based on binary_level ===\n",
        "for _, row in df.iterrows():\n",
        "    fname = f\"{row['id_code']}.jpeg\"\n",
        "    label = row[\"binary_level\"]\n",
        "\n",
        "    src_path = os.path.join(input_images_folder, fname)\n",
        "    dst_path = os.path.join(no_dr_folder if label == 0 else dr_folder, fname)\n",
        "\n",
        "    if os.path.exists(src_path):\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "print(f\"âœ… Images split into {no_dr_folder} and {dr_folder} based on binary labels.\")\n"
      ],
      "metadata": {
        "id": "v9kaKyMNWlLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "# === Paths ===\n",
        "filtered_csv_path = \"/content/drive/MyDrive/EECE 490 Project/Aptos/train_cleaned.csv\"\n",
        "output_folder = \"/content/drive/MyDrive/EECE 490 Project/Aptos/train_images_cleaned\"\n",
        "balanced_csv_path = \"/content/drive/MyDrive/EECE 490 Project/Aptos/train_balanced.csv\"\n",
        "balanced_images_folder = \"/content/drive/MyDrive/EECE 490 Project/Aptos/train_images_balanced\"\n",
        "os.makedirs(balanced_images_folder, exist_ok=True)\n",
        "\n",
        "# === Load filtered CSV ===\n",
        "df_filtered = pd.read_csv(filtered_csv_path)\n",
        "\n",
        "# === Add binary label column ===\n",
        "df_filtered['binary_level'] = df_filtered['diagnosis'].apply(lambda x: 0 if x == 0 else 1)\n",
        "\n",
        "# === Balance the dataset ===\n",
        "min_count = df_filtered['binary_level'].value_counts().min()\n",
        "df_balanced = pd.concat([\n",
        "    df_filtered[df_filtered['binary_level'] == 0].sample(min_count, random_state=42),\n",
        "    df_filtered[df_filtered['binary_level'] == 1].sample(min_count, random_state=42)\n",
        "]).reset_index(drop=True)\n",
        "\n",
        "# === Save balanced CSV ===\n",
        "df_balanced.to_csv(balanced_csv_path, index=False)\n",
        "print(f\"âœ… Balanced CSV file saved to: {balanced_csv_path}\")\n",
        "\n",
        "# === Copy images to Balanced_Images folder ===\n",
        "for fname in df_balanced['id_code']:\n",
        "    src = os.path.join(output_folder, f\"{fname}.jpeg\")\n",
        "    dst = os.path.join(balanced_images_folder, f\"{fname}.jpeg\")\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "print(f\"âœ… {len(df_balanced)} images copied to: {balanced_images_folder}\")\n"
      ],
      "metadata": {
        "id": "nA2OzXR3XjM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "# === Paths ===\n",
        "balanced_csv_path = \"/content/drive/MyDrive/EECE 490 Project/Aptos/train_balanced.csv\"\n",
        "balanced_images_folder = \"/content/drive/MyDrive/EECE 490 Project/Aptos/train_images_balanced\"\n",
        "split_folder = \"/content/drive/MyDrive/EECE 490 Project/Aptos/train_images_split\"\n",
        "dr_folder = os.path.join(split_folder, \"DR\")\n",
        "no_dr_folder = os.path.join(split_folder, \"NoDR\")\n",
        "\n",
        "# === Create target folders ===\n",
        "os.makedirs(dr_folder, exist_ok=True)\n",
        "os.makedirs(no_dr_folder, exist_ok=True)\n",
        "\n",
        "# === Load balanced CSV ===\n",
        "df_balanced = pd.read_csv(balanced_csv_path)\n",
        "\n",
        "# === Copy images to corresponding folders ===\n",
        "for _, row in df_balanced.iterrows():\n",
        "    fname = f\"{row['id_code']}.jpeg\"\n",
        "    label = row['binary_level']\n",
        "\n",
        "    src = os.path.join(balanced_images_folder, fname)\n",
        "    dst = os.path.join(dr_folder if label == 1 else no_dr_folder, fname)\n",
        "\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "print(\"âœ… Images split into DR and NoDR folders successfully!\")\n"
      ],
      "metadata": {
        "id": "m06ov7GHYXEV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}