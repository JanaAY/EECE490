{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "520jj5THZIHc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "# === Load original grading CSV ===\n",
        "original_csv = \"/content/drive/MyDrive/EECE 490 Project/IDRD/b. IDRiD_Disease Grading_Testing Labels.csv\"\n",
        "df = pd.read_csv(original_csv)\n",
        "\n",
        "# === Generate new filenames ===\n",
        "new_ids = [f\"IDRid_{i:03d}\" for i in range(414, 414 + len(df))]\n",
        "df[\"filename\"] = new_ids\n",
        "\n",
        "# === Save updated Excel ===\n",
        "output_csv = \"/content/drive/MyDrive/EECE 490 Project/IDRD/updated_test.csv\"\n",
        "os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
        "df.to_csv(output_csv, index=False)\n",
        "print(\"✅ New CSV saved:\", output_csv)\n",
        "\n",
        "# === Paths for images ===\n",
        "original_img_folder = \"/content/drive/MyDrive/EECE 490 Project/IDRD/1. Original Images/b. Testing Set\"\n",
        "new_img_folder = \"/content/drive/MyDrive/EECE 490 Project/IDRD/1. Original Images/Testing_updated\"\n",
        "os.makedirs(new_img_folder, exist_ok=True)\n",
        "\n",
        "# === List of old filenames in order ===\n",
        "old_filenames = sorted(os.listdir(original_img_folder))\n",
        "old_filenames = [f for f in old_filenames if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "old_filenames = sorted(old_filenames)[:len(new_ids)]  # Make sure we only map the correct count\n",
        "\n",
        "# === Rename and copy preserving order ===\n",
        "for old_name, new_id in zip(old_filenames, new_ids):\n",
        "    ext = os.path.splitext(old_name)[1]  # Keep original extension\n",
        "    new_name = new_id + ext\n",
        "    src = os.path.join(original_img_folder, old_name)\n",
        "    dst = os.path.join(new_img_folder, new_name)\n",
        "    shutil.copy2(src, dst)\n",
        "\n",
        "print(f\"✅ {len(new_ids)} images renamed & copied to:\", new_img_folder)\n"
      ],
      "metadata": {
        "id": "x8bFRC0Bk8BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "# === Image Folders ===\n",
        "folder1 = \"/content/drive/MyDrive/EECE 490 Project/IDRD/1. Original Images/Testing_updated\"\n",
        "folder2 = \"/content/drive/MyDrive/EECE 490 Project/IDRD/1. Original Images/a. Training Set\"\n",
        "combined_folder = \"/content/drive/MyDrive/EECE 490 Project/IDRD/1. Original Images/Combined\"\n",
        "os.makedirs(combined_folder, exist_ok=True)\n",
        "\n",
        "# === Copy and Rename Images to .jpej ===\n",
        "for folder in [folder1, folder2]:\n",
        "    for fname in os.listdir(folder):\n",
        "        if fname.lower().endswith(\".jpg\"):\n",
        "            name_no_ext = os.path.splitext(fname)[0]\n",
        "            new_name = name_no_ext + \".jpeg\"\n",
        "            src = os.path.join(folder, fname)\n",
        "            dst = os.path.join(combined_folder, new_name)\n",
        "            shutil.copy2(src, dst)\n",
        "\n",
        "print(\"✅ All images copied and renamed to .jpeg!\")\n",
        "\n",
        "# === Excel Paths ===\n",
        "train_excel = \"/content/drive/MyDrive/EECE 490 Project/IDRD/a. IDRiD_Disease Grading_Training Labels.xlsx\"\n",
        "test_excel = \"/content/drive/MyDrive/EECE 490 Project/IDRD/updated_test.xlsx\"\n",
        "\n",
        "# === Load Excel Files as-is ===\n",
        "df_train = pd.read_excel(train_excel)\n",
        "df_test = pd.read_excel(test_excel)\n",
        "\n",
        "# === Merge without modifying columns ===\n",
        "combined_df = pd.concat([df_train, df_test], ignore_index=True)\n",
        "\n",
        "# === Save merged Excel ===\n",
        "out_path = \"/content/drive/MyDrive/EECE 490 Project/IDRD/combined_labels.xlsx\"\n",
        "combined_df.to_excel(out_path, index=False)\n",
        "\n",
        "print(\"✅ Excel (all 3 columns) combined and saved to:\", out_path)\n"
      ],
      "metadata": {
        "id": "W2hWYrTAyaji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Imports ===\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# === Black Border Remover ===\n",
        "def remove_black_border(img, threshold=5):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours:\n",
        "        return img\n",
        "    x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
        "    return img[y:y+h, x:x+w]\n",
        "\n",
        "# === Auto Flip if Left Eye ===\n",
        "def auto_flip_if_left_eye(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    h, w = gray.shape\n",
        "    left = np.mean(gray[:, :w//2])\n",
        "    right = np.mean(gray[:, w//2:])\n",
        "    if right > left:\n",
        "        return cv2.flip(img, 1)  # horizontal flip\n",
        "    return img\n",
        "\n",
        "# === Full Preprocessing Pipeline (Resizing moved to end) ===\n",
        "def preprocess_image_full(img, target_size=(512, 512), blur_thresh=20.0, brightness_thresh=25):\n",
        "    try:\n",
        "        if img is None or len(img.shape) != 3 or img.shape[2] != 3:\n",
        "            return None\n",
        "\n",
        "        # Blur and brightness checks\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        if cv2.Laplacian(gray, cv2.CV_64F).var() < blur_thresh:\n",
        "            return None\n",
        "        if np.mean(gray) < brightness_thresh:\n",
        "            return None\n",
        "\n",
        "        # Remove black borders\n",
        "        img = remove_black_border(img)\n",
        "\n",
        "        # Auto flip if left eye\n",
        "        img = auto_flip_if_left_eye(img)\n",
        "\n",
        "        # CLAHE enhancement\n",
        "        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "        l = clahe.apply(l)\n",
        "        img = cv2.cvtColor(cv2.merge((l, a, b)), cv2.COLOR_LAB2BGR)\n",
        "\n",
        "        # Glare detection\n",
        "        glare_mask = cv2.inRange(img, (240, 240, 240), (255, 255, 255))\n",
        "        contours, _ = cv2.findContours(glare_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if any(cv2.contourArea(c) > 500 for c in contours):\n",
        "            return None\n",
        "\n",
        "        # Text/annotation filter\n",
        "        mask_text = cv2.inRange(img, (220, 220, 220), (255, 255, 255))\n",
        "        if cv2.countNonZero(mask_text) > 3000:\n",
        "            return None\n",
        "\n",
        "        # Dark region filter\n",
        "        if np.mean(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) > 10) < 0.2:\n",
        "            return None\n",
        "\n",
        "        # ✅ Resize (critical fix)\n",
        "        img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        # ✅ Validate shape before return\n",
        "        if img.shape != (512, 512, 3):\n",
        "            raise ValueError(f\"Resized image has invalid shape: {img.shape}\")\n",
        "\n",
        "        # Normalize to [-1, 1]\n",
        "        return img.astype(np.float32) / 127.5 - 1.0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Exception during processing: {e}\")\n",
        "        return None\n",
        "\n",
        "# === Set Input/Output Folders ===\n",
        "input_folder = \"/content/drive/MyDrive/EECE 490 Project/IDRD/1. Original Images/Combined\"\n",
        "output_folder = \"/content/drive/MyDrive/EECE 490 Project/IDRD/Cleaned_IDRiD\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# === Run Preprocessing ===\n",
        "skipped = []\n",
        "image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.jpeg'))]\n",
        "sample_images = []\n",
        "\n",
        "for fname in tqdm(image_files):\n",
        "    in_path = os.path.join(input_folder, fname)\n",
        "    out_path = os.path.join(output_folder, fname)\n",
        "\n",
        "    img = cv2.imread(in_path)\n",
        "    if img is None:\n",
        "        skipped.append(fname)\n",
        "        continue\n",
        "\n",
        "    processed = preprocess_image_full(img)\n",
        "    if processed is None:\n",
        "        skipped.append(fname)\n",
        "        continue\n",
        "    if processed.shape != (512, 512, 3):\n",
        "        print(f\"⚠️ Unexpected size in {fname}: {processed.shape}\")\n",
        "        skipped.append(fname)\n",
        "        continue\n",
        "\n",
        "    out_img = ((processed + 1.0) * 127.5).astype(np.uint8)\n",
        "    cv2.imwrite(out_path, out_img)\n",
        "\n",
        "    if len(sample_images) < 10 and random.random() < 0.1:\n",
        "        sample_images.append(cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "# === Show Random Previews ===\n",
        "if sample_images:\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    for i, img in enumerate(sample_images):\n",
        "        plt.subplot(1, len(sample_images), i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"⚠️ No sample images to display.\")\n",
        "\n",
        "print(f\"\\n✅ Done! Preprocessed images saved to: {output_folder} | Skipped {len(skipped)} bad images.\")\n"
      ],
      "metadata": {
        "id": "amfdhhHoybFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# === Folder containing images ===\n",
        "folder_path = \"/content/drive/MyDrive/EECE 490 Project/IDRD/Cleaned_IDRiD\"\n",
        "\n",
        "# === Loop through all files and check dimensions ===\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"❌ Could not read {filename}\")\n",
        "            continue\n",
        "\n",
        "        h, w = img.shape[:2]\n",
        "        if h != 512 or w != 512:\n",
        "            print(f\"⚠️ {filename} has size {w}x{h}\")\n"
      ],
      "metadata": {
        "id": "Rb2Yo6CY5Qr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_images = [f for f in os.listdir(output_folder) if f.lower().endswith(('.jpeg', '.jpg', '.png'))]\n",
        "print(f\"🧼 Number of cleaned images: {len(cleaned_images)}\")\n"
      ],
      "metadata": {
        "id": "CeI0f7US5X4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# === Load the combined Excel file ===\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/EECE 490 Project/IDRD/combined_labels.xlsx\")\n",
        "\n",
        "# === Force all filenames to end in .jpeg ===\n",
        "df['filename'] = df['filename'].astype(str).apply(lambda x: os.path.splitext(x)[0] + \".jpeg\")\n",
        "\n",
        "# === Path where your .jpej images are stored ===\n",
        "output_folder = \"/content/drive/MyDrive/EECE 490 Project/IDRD/Cleaned_IDRiD\"\n",
        "kept_images = set(os.listdir(output_folder))\n",
        "\n",
        "# === Filter the dataframe by available image files ===\n",
        "df_filtered = df[df['filename'].isin(kept_images)]\n",
        "\n",
        "# === Count and display label distribution ===\n",
        "label_counts = df_filtered['diagnosis'].value_counts().sort_index()\n",
        "for i in range(5):\n",
        "    print(f\"  DR ({i}): {label_counts.get(i, 0)}\")\n",
        "\n",
        "# === Save the filtered DataFrame to a new Excel file ===\n",
        "output_excel_path = \"/content/drive/MyDrive/EECE 490 Project/IDRD/cleaned_labels.xlsx\"\n",
        "df_filtered.to_excel(output_excel_path, index=False)\n",
        "\n",
        "print(f\"\\n✅ Filtered Excel file saved to: {output_excel_path}\")\n"
      ],
      "metadata": {
        "id": "5mU_-zNx5bnd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}