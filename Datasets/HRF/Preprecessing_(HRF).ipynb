{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOKqRSo9-uYw"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# === Base path where all DR folders are ===\n",
        "base_dir = \"/content/drive/MyDrive/EECE 490 Project/RandSet2\"\n",
        "\n",
        "# === New output folder ===\n",
        "output_dir = os.path.join(base_dir, \"All_Images\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === Folder names to merge ===\n",
        "dr_folders = [\n",
        "    \"No DR signs\",\n",
        "    \"Mild (or early) NPDR\",\n",
        "    \"Moderate NPDR\",\n",
        "    \"Severe NPDR\",\n",
        "    \"Very Severe NPDR\",\n",
        "    \"PDR\",\n",
        "    \"Advanced PDR\"\n",
        "]\n",
        "\n",
        "# === Copy all images without renaming ===\n",
        "for folder in dr_folders:\n",
        "    folder_path = os.path.join(base_dir, folder)\n",
        "    if not os.path.isdir(folder_path):\n",
        "        print(f\"âš ï¸ Folder not found: {folder_path}\")\n",
        "        continue\n",
        "\n",
        "    for fname in os.listdir(folder_path):\n",
        "        if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "            src = os.path.join(folder_path, fname)\n",
        "            dst = os.path.join(output_dir, fname)  # âš ï¸ no renaming here!\n",
        "            shutil.copy2(src, dst)\n",
        "\n",
        "print(f\"\\nâœ… Done! All images copied without renaming to: {output_dir}\")\n"
      ],
      "metadata": {
        "id": "J61AQj_H_aAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# === Base paths ===\n",
        "base_dir = \"/content/drive/MyDrive/EECE 490 Project/RandSet2\"\n",
        "input_dir = os.path.join(base_dir, \"All_Images\")\n",
        "output_dir = os.path.join(base_dir, \"All_Images_JPEG\")\n",
        "\n",
        "# === Create output directory ===\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === Copy & Rename ===\n",
        "count = 0\n",
        "for fname in os.listdir(input_dir):\n",
        "    if fname.lower().endswith((\".jpg\", \".jpeg\")):\n",
        "        name_wo_ext = os.path.splitext(fname)[0]\n",
        "        src = os.path.join(input_dir, fname)\n",
        "        dst = os.path.join(output_dir, name_wo_ext + \".jpeg\")\n",
        "        shutil.copy2(src, dst)\n",
        "        count += 1\n",
        "\n",
        "print(f\"âœ… Copied and renamed {count} image(s) to .jpeg in: {output_dir}\")\n"
      ],
      "metadata": {
        "id": "D1TxyMtQAn3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# === Base path ===\n",
        "base_dir = \"/content/drive/MyDrive/EECE 490 Project/RandSet2\"\n",
        "output_excel = os.path.join(base_dir, \"DR_Graded_Metadata.xlsx\")\n",
        "\n",
        "# === DR class mapping ===\n",
        "dr_mapping = {\n",
        "    \"No DR signs\": 0,\n",
        "    \"Mild (or early) NPDR\": 1,\n",
        "    \"Moderate NPDR\": 2,\n",
        "    \"Severe NPDR\": 3,\n",
        "    \"Very Severe NPDR\": 4,\n",
        "    \"PDR\": 5,\n",
        "    \"Advanced PDR\": 6\n",
        "}\n",
        "\n",
        "# === Output data list ===\n",
        "data = []\n",
        "\n",
        "# === Loop through folders and collect filenames + labels ===\n",
        "for folder_name, label in dr_mapping.items():\n",
        "    folder_path = os.path.join(base_dir, folder_name)\n",
        "    if not os.path.isdir(folder_path):\n",
        "        print(f\"âš ï¸ Folder not found: {folder_path}\")\n",
        "        continue\n",
        "\n",
        "    for fname in os.listdir(folder_path):\n",
        "        if fname.lower().endswith((\".jpg\", \".jpeg\")):\n",
        "            data.append({\n",
        "                \"Filename\": fname,\n",
        "                \"Format\": \"jpeg\",\n",
        "                \"Status\": label\n",
        "            })\n",
        "\n",
        "# === Save metadata to Excel ===\n",
        "df = pd.DataFrame(data)\n",
        "df.to_excel(output_excel, index=False)\n",
        "\n",
        "print(f\"âœ… Excel metadata saved to: {output_excel}\")\n"
      ],
      "metadata": {
        "id": "3wzGppl2ApnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# === Path to original Excel file ===\n",
        "input_excel = \"/content/drive/MyDrive/EECE 490 Project/RandSet2/Manual classification of fundus images with diabetic retinopathy conditions.xlsx\"  # Replace with your actual filename\n",
        "output_excel = \"/content/drive/MyDrive/EECE 490 Project/RandSet2/DR_Graded_Metadata.xlsx\"\n",
        "\n",
        "# === DR stage to numeric mapping ===\n",
        "dr_mapping = {\n",
        "    \"No DR signs\": 0,\n",
        "    \"Mild (or early) NPDR\": 1,\n",
        "    \"Moderate NPDR\": 2,\n",
        "    \"Severe NPDR\": 3,\n",
        "    \"Very Severe NPDR\": 4,\n",
        "    \"PDR\": 5,\n",
        "    \"Advanced PDR\": 6\n",
        "}\n",
        "\n",
        "# === Load original metadata ===\n",
        "df = pd.read_excel(input_excel)\n",
        "\n",
        "# === Map stage names to numeric values ===\n",
        "df[\"Status\"] = df[\"Status\"].map(dr_mapping)  # Assuming column name is 'Stage' or similar\n",
        "\n",
        "# === Create a new 'Filename' column with '.jpeg' extension ===\n",
        "df[\"Image\"] = df[\"Image\"].apply(lambda x: str(x).split('.')[0] + \".jpeg\")  # Assuming image column is named 'Image'\n",
        "\n",
        "# === Save to NEW Excel file ===\n",
        "df.to_excel(output_excel, index=False)\n",
        "\n",
        "print(f\"âœ… New metadata Excel saved to: {output_excel}\")\n"
      ],
      "metadata": {
        "id": "agYn9tcO80bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === Load the Excel file ===\n",
        "excel_path = \"/content/drive/MyDrive/EECE 490 Project/RandSet2/DR_Graded_Metadata.xlsx\"\n",
        "df = pd.read_excel(excel_path)\n",
        "\n",
        "# === Count distribution ===\n",
        "grade_counts = df[\"Status\"].value_counts().sort_index()\n",
        "\n",
        "# === Print results ===\n",
        "print(\"ðŸ“Š DR Grade Distribution:\")\n",
        "for grade, count in grade_counts.items():\n",
        "    print(f\"Grade {grade}: {count} images\")\n"
      ],
      "metadata": {
        "id": "IwsQ1KNpBnAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Imports ===\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# === Black Border Remover ===\n",
        "def remove_black_border(img, threshold=5):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours:\n",
        "        return img\n",
        "    x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
        "    return img[y:y+h, x:x+w]\n",
        "\n",
        "# === Auto Flip if Left Eye ===\n",
        "def auto_flip_if_left_eye(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    h, w = gray.shape\n",
        "    left = np.mean(gray[:, :w//2])\n",
        "    right = np.mean(gray[:, w//2:])\n",
        "    if right > left:\n",
        "        return cv2.flip(img, 1)  # horizontal flip\n",
        "    return img\n",
        "\n",
        "# === Full Preprocessing Pipeline (Resizing moved to end) ===\n",
        "def preprocess_image_full(img, target_size=(512, 512), blur_thresh=20.0, brightness_thresh=25):\n",
        "    try:\n",
        "        if img is None or len(img.shape) != 3 or img.shape[2] != 3:\n",
        "            return None\n",
        "\n",
        "        # Blur and brightness checks\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        if cv2.Laplacian(gray, cv2.CV_64F).var() < blur_thresh:\n",
        "            return None\n",
        "        if np.mean(gray) < brightness_thresh:\n",
        "            return None\n",
        "\n",
        "        # Remove black borders\n",
        "        img = remove_black_border(img)\n",
        "\n",
        "        # Auto flip if left eye\n",
        "        img = auto_flip_if_left_eye(img)\n",
        "\n",
        "        # CLAHE enhancement\n",
        "        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "        l = clahe.apply(l)\n",
        "        img = cv2.cvtColor(cv2.merge((l, a, b)), cv2.COLOR_LAB2BGR)\n",
        "\n",
        "        # Glare detection\n",
        "        glare_mask = cv2.inRange(img, (240, 240, 240), (255, 255, 255))\n",
        "        contours, _ = cv2.findContours(glare_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if any(cv2.contourArea(c) > 500 for c in contours):\n",
        "            return None\n",
        "\n",
        "        # Text/annotation filter\n",
        "        mask_text = cv2.inRange(img, (220, 220, 220), (255, 255, 255))\n",
        "        if cv2.countNonZero(mask_text) > 3000:\n",
        "            return None\n",
        "\n",
        "        # Dark region filter\n",
        "        if np.mean(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) > 10) < 0.2:\n",
        "            return None\n",
        "\n",
        "        # âœ… Resize (critical fix)\n",
        "        img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        # âœ… Validate shape before return\n",
        "        if img.shape != (512, 512, 3):\n",
        "            raise ValueError(f\"Resized image has invalid shape: {img.shape}\")\n",
        "\n",
        "        # Normalize to [-1, 1]\n",
        "        return img.astype(np.float32) / 127.5 - 1.0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Exception during processing: {e}\")\n",
        "        return None\n",
        "\n",
        "# === Set Input/Output Folders ===\n",
        "input_folder = \"/content/drive/MyDrive/EECE 490 Project/RandSet2/All_Images_JPEG\"\n",
        "output_folder = \"/content/drive/MyDrive/EECE 490 Project/RandSet2/All_Images_Cleaned\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# === Run Preprocessing ===\n",
        "skipped = []\n",
        "image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.jpeg', '.jpg', '.png'))]\n",
        "sample_images = []\n",
        "\n",
        "for fname in tqdm(image_files):\n",
        "    in_path = os.path.join(input_folder, fname)\n",
        "    out_path = os.path.join(output_folder, fname)\n",
        "\n",
        "    img = cv2.imread(in_path)\n",
        "    if img is None:\n",
        "        skipped.append(fname)\n",
        "        continue\n",
        "\n",
        "    processed = preprocess_image_full(img)\n",
        "    if processed is None:\n",
        "        skipped.append(fname)\n",
        "        continue\n",
        "    if processed.shape != (512, 512, 3):\n",
        "        print(f\"âš ï¸ Unexpected size in {fname}: {processed.shape}\")\n",
        "        skipped.append(fname)\n",
        "        continue\n",
        "\n",
        "    out_img = ((processed + 1.0) * 127.5).astype(np.uint8)\n",
        "    cv2.imwrite(out_path, out_img)\n",
        "\n",
        "    if len(sample_images) < 10 and random.random() < 0.1:\n",
        "        sample_images.append(cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "# === Show Random Previews ===\n",
        "if sample_images:\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    for i, img in enumerate(sample_images):\n",
        "        plt.subplot(1, len(sample_images), i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"âš ï¸ No sample images to display.\")\n",
        "\n",
        "print(f\"\\nâœ… Done! Preprocessed images saved to: {output_folder} | Skipped {len(skipped)} bad images.\")\n"
      ],
      "metadata": {
        "id": "PWiNkXAVFrTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# === Folder containing images ===\n",
        "folder_path = \"/content/drive/MyDrive/EECE 490 Project/RandSet2/All_Images_Cleaned\"\n",
        "\n",
        "# === Loop through all files and check dimensions ===\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"âŒ Could not read {filename}\")\n",
        "            continue\n",
        "\n",
        "        h, w = img.shape[:2]\n",
        "        if h != 512 or w != 512:\n",
        "            print(f\"âš ï¸ {filename} has size {w}x{h}\")\n"
      ],
      "metadata": {
        "id": "kxK6YvtSCeqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_images = [f for f in os.listdir(output_folder) if f.lower().endswith(('.jpeg', '.jpg', '.png'))]\n",
        "print(f\"ðŸ§¼ Number of cleaned images: {len(cleaned_images)}\")\n"
      ],
      "metadata": {
        "id": "yaiEiSNAGn1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# === Load the combined Excel file ===\n",
        "excel_path = \"/content/drive/MyDrive/EECE 490 Project/RandSet2/DR_Graded_Metadata.xlsx\"\n",
        "df = pd.read_excel(excel_path)\n",
        "\n",
        "# === Define where your JPEG images are stored ===\n",
        "output_folder = \"/content/drive/MyDrive/EECE 490 Project/RandSet2/All_Images_Cleaned\"\n",
        "kept_images = set(os.listdir(output_folder))\n",
        "\n",
        "# === Filter rows based on available images ===\n",
        "df_filtered = df[df['Image'].isin(kept_images)]\n",
        "\n",
        "# === Count and display label distribution ===\n",
        "label_counts = df_filtered['Status'].value_counts().sort_index()\n",
        "count_0 = label_counts.get(0, 0)\n",
        "count_1 = label_counts.get(1, 0)\n",
        "count_2 = label_counts.get(2, 0)\n",
        "count_3 = label_counts.get(3, 0)\n",
        "count_4 = label_counts.get(4, 0)\n",
        "count_5 = label_counts.get(5, 0)\n",
        "count_6 = label_counts.get(6, 0)\n",
        "\n",
        "print(f\"âœ… Remaining samples:\\n  No_DR (0): {count_0}\\n  DR (1): {count_1}\\n  DR (2): {count_2}\\n  DR (3): {count_3}\\n  DR (4): {count_4}\\n  DR (5): {count_5}\\n  DR (6): {count_6}\")\n",
        "\n",
        "# === Save the filtered dataframe to a new Excel file ===\n",
        "output_excel_path = \"/content/drive/MyDrive/EECE 490 Project/RandSet2/DR_Graded_Cleaned.xlsx\"\n",
        "df_filtered.to_excel(output_excel_path, index=False)\n",
        "\n",
        "print(f\"\\nðŸ“ Filtered Excel file saved to: {output_excel_path}\")\n"
      ],
      "metadata": {
        "id": "vn9otQSwGsnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "# === Paths ===\n",
        "base_dir = \"/content/drive/MyDrive/EECE 490 Project/RandSet2\"\n",
        "input_excel = os.path.join(base_dir, \"DR_Graded_Cleaned.xlsx\")\n",
        "input_images_folder = os.path.join(base_dir, \"All_Images_Cleaned\")\n",
        "output_excel = os.path.join(base_dir, \"DR_Unbalanced_Split.xlsx\")\n",
        "output_split_folder = os.path.join(base_dir, \"Unbalanced_Split\")\n",
        "no_dr_folder = os.path.join(output_split_folder, \"NoDR\")\n",
        "dr_folder = os.path.join(output_split_folder, \"DR\")\n",
        "\n",
        "# === Step 1: Load Excel and add binary_level column ===\n",
        "df = pd.read_excel(input_excel)\n",
        "df[\"binary_level\"] = df[\"Status\"].apply(lambda x: 0 if x == 0 else 1)\n",
        "\n",
        "# === Step 2: Save new Excel file ===\n",
        "df.to_excel(output_excel, index=False)\n",
        "print(f\"âœ… New Excel file saved to: {output_excel}\")\n",
        "\n",
        "# === Step 3: Create output folders ===\n",
        "os.makedirs(no_dr_folder, exist_ok=True)\n",
        "os.makedirs(dr_folder, exist_ok=True)\n",
        "\n",
        "# === Step 4: Copy images based on binary_level ===\n",
        "for _, row in df.iterrows():\n",
        "    fname = row[\"Image\"]\n",
        "    label = row[\"binary_level\"]\n",
        "\n",
        "    src_path = os.path.join(input_images_folder, fname)\n",
        "    dst_path = os.path.join(no_dr_folder if label == 0 else dr_folder, fname)\n",
        "\n",
        "    if os.path.exists(src_path):\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "print(f\"âœ… Images split into {no_dr_folder} and {dr_folder} based on binary labels.\")\n"
      ],
      "metadata": {
        "id": "PWrPrqBQJgb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "# === Paths ===\n",
        "filtered_excel_path = \"/content/drive/MyDrive/EECE 490 Project/RandSet2/DR_Graded_Cleaned.xlsx\"\n",
        "output_folder = \"/content/drive/MyDrive/EECE 490 Project/RandSet2/All_Images_Cleaned\"\n",
        "balanced_excel_path = \"/content/drive/MyDrive/EECE 490 Project/RandSet2/DR_Graded_Balanced.xlsx\"\n",
        "balanced_images_folder = \"/content/drive/MyDrive/EECE 490 Project/RandSet2/All_Images_Balanced\"\n",
        "os.makedirs(balanced_images_folder, exist_ok=True)\n",
        "\n",
        "# === Load filtered Excel ===\n",
        "df_filtered = pd.read_excel(filtered_excel_path)\n",
        "\n",
        "# === Add binary label column ===\n",
        "df_filtered['binary_level'] = df_filtered['Status'].apply(lambda x: 0 if x == 0 else 1)\n",
        "\n",
        "# === Balance the dataset ===\n",
        "min_count = df_filtered['binary_level'].value_counts().min()\n",
        "df_balanced = pd.concat([\n",
        "    df_filtered[df_filtered['binary_level'] == 0].sample(min_count, random_state=42),\n",
        "    df_filtered[df_filtered['binary_level'] == 1].sample(min_count, random_state=42)\n",
        "]).reset_index(drop=True)\n",
        "\n",
        "# === Save balanced Excel ===\n",
        "df_balanced.to_excel(balanced_excel_path, index=False)\n",
        "print(f\"âœ… Balanced Excel file saved to: {balanced_excel_path}\")\n",
        "\n",
        "# === Copy images to Balanced_Images folder ===\n",
        "for fname in df_balanced['Image']:\n",
        "    src = os.path.join(output_folder, fname)\n",
        "    dst = os.path.join(balanced_images_folder, fname)\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "print(f\"âœ… {len(df_balanced)} images copied to: {balanced_images_folder}\")\n"
      ],
      "metadata": {
        "id": "58aAk8Y_Hp_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Count binary label distribution in balanced dataset ===\n",
        "binary_counts = df_balanced['binary_level'].value_counts().sort_index()\n",
        "count_0 = binary_counts.get(0, 0)\n",
        "count_1 = binary_counts.get(1, 0)\n",
        "\n",
        "print(f\"ðŸ“Š Class Distribution in Balanced excel:\\n  No_DR (0): {count_0}\\n  DR (1): {count_1}\")\n"
      ],
      "metadata": {
        "id": "GZBFDBIJIgfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "# === Paths ===\n",
        "balanced_excel_path = \"/content/drive/MyDrive/EECE 490 Project/RandSet2/DR_Graded_Balanced.xlsx\"\n",
        "balanced_images_folder = \"/content/drive/MyDrive/EECE 490 Project/RandSet2/All_Images_Balanced\"\n",
        "split_folder = \"/content/drive/MyDrive/EECE 490 Project/RandSet2/All_Split_Balanced\"\n",
        "dr_folder = os.path.join(split_folder, \"DR\")\n",
        "no_dr_folder = os.path.join(split_folder, \"NoDR\")\n",
        "\n",
        "# === Create target folders ===\n",
        "os.makedirs(dr_folder, exist_ok=True)\n",
        "os.makedirs(no_dr_folder, exist_ok=True)\n",
        "\n",
        "# === Load balanced Excel ===\n",
        "df_balanced = pd.read_excel(balanced_excel_path)\n",
        "\n",
        "# === Copy images to corresponding folders ===\n",
        "for _, row in df_balanced.iterrows():\n",
        "    fname = row['Image']\n",
        "    label = row['binary_level']\n",
        "\n",
        "    src = os.path.join(balanced_images_folder, fname)\n",
        "    dst = os.path.join(dr_folder if label == 1 else no_dr_folder, fname)\n",
        "\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "print(\"âœ… Images split into DR and NoDR folders successfully!\")\n"
      ],
      "metadata": {
        "id": "Cc0yw2-PIq8a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}