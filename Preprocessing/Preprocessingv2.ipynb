{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "3btje0_Vt1LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Paths ===\n",
        "image_folders = [\n",
        "    \"/content/drive/MyDrive/EECE 490 Project/EyePac/Cleaned_images\",\n",
        "    \"/content/drive/MyDrive/EECE 490 Project/DDR dataset/Cleaned_DDR\",\n",
        "    \"/content/drive/MyDrive/EECE 490 Project/Aptos/train_images_cleaned\",\n",
        "    \"/content/drive/MyDrive/EECE 490 Project/IDRD/Cleaned_IDRiD\"\n",
        "]\n",
        "\n",
        "combined_image_folder = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/All_Images\"\n",
        "os.makedirs(combined_image_folder, exist_ok=True)\n",
        "\n",
        "# === Combine Images ===\n",
        "for folder in image_folders:\n",
        "    for file in os.listdir(folder):\n",
        "        src = os.path.join(folder, file)\n",
        "        dst = os.path.join(combined_image_folder, file)\n",
        "        if os.path.isfile(src):\n",
        "            shutil.copy2(src, dst)\n",
        "\n",
        "print(\"‚úÖ All images copied to:\", combined_image_folder)"
      ],
      "metadata": {
        "id": "AqrjxJHon80e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# === Excel Files to Combine ===\n",
        "excel_paths = [\n",
        "    \"/content/drive/MyDrive/EECE 490 Project/EyePac/trainLabels_filtered.xlsx\",\n",
        "    \"/content/drive/MyDrive/EECE 490 Project/DDR dataset/DR_grading_cleaned.xlsx\",\n",
        "    \"/content/drive/MyDrive/EECE 490 Project/Aptos/train_cleaned.xlsx\",\n",
        "    \"/content/drive/MyDrive/EECE 490 Project/IDRD/cleaned_labels.xlsx\",\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for path in excel_paths:\n",
        "    df = pd.read_excel(path)\n",
        "    if \"filename\" in df.columns and \"diagnosis\" in df.columns:\n",
        "        dfs.append(df[[\"filename\", \"diagnosis\"]])\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Columns missing in: {path}\")\n",
        "\n",
        "# === Merge and Save ===\n",
        "combined_df = pd.concat(dfs, ignore_index=True)\n",
        "combined_excel_path = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/combined_labels.xlsx\"\n",
        "combined_df.to_excel(combined_excel_path, index=False)\n",
        "\n",
        "print(\"‚úÖ Combined Excel saved at:\", combined_excel_path)\n"
      ],
      "metadata": {
        "id": "NjCdBDe9t1SG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Count number of images in folder ===\n",
        "num_images = len(os.listdir(\"/content/drive/MyDrive/EECE 490 Project/Classification_Set/All_Images\"))\n",
        "\n",
        "# === Count number of rows in Excel ===\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/EECE 490 Project/Classification_Set/combined_labels.xlsx\")\n",
        "num_labels = len(df)\n",
        "\n",
        "# === Print results ===\n",
        "print(f\"üñºÔ∏è Total images in folder: {num_images}\")\n",
        "print(f\"üìÑ Total labels in Excel:  {num_labels}\")\n"
      ],
      "metadata": {
        "id": "Ij0-6m8UpBjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm  # <--- progress bar\n",
        "\n",
        "# === Paths ===\n",
        "combined_excel_path = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/combined_labels.xlsx\"\n",
        "image_dir = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/All_Images\"\n",
        "output_dir = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/renamed_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === Load Excel\n",
        "df = pd.read_excel(combined_excel_path)\n",
        "\n",
        "# === Prepare new list\n",
        "new_filenames = []\n",
        "preserved_diagnoses = []\n",
        "image_counter = 1\n",
        "not_found = []\n",
        "\n",
        "# === Loop through Excel with tqdm\n",
        "for row in tqdm(df.itertuples(index=False), total=len(df), desc=\"Processing\"):\n",
        "    original_name = os.path.splitext(str(row.filename))[0]\n",
        "    label = row.diagnosis\n",
        "    found = False\n",
        "\n",
        "    for ext in ['.jpeg', '.jpg', '.JPG', '.JPEG']:\n",
        "        image_path = os.path.join(image_dir, original_name + ext)\n",
        "        if os.path.exists(image_path):\n",
        "            new_filename = f\"img_{image_counter:05d}.png\"\n",
        "            img = Image.open(image_path).convert(\"RGB\")\n",
        "            img.save(os.path.join(output_dir, new_filename))\n",
        "\n",
        "            new_filenames.append(new_filename)\n",
        "            preserved_diagnoses.append(label)\n",
        "            image_counter += 1\n",
        "            found = True\n",
        "            break\n",
        "\n",
        "    if not found:\n",
        "        not_found.append(original_name)\n",
        "\n",
        "# === Save updated Excel\n",
        "renamed_df = pd.DataFrame({\n",
        "    \"filename\": new_filenames,\n",
        "    \"diagnosis\": preserved_diagnoses\n",
        "})\n",
        "renamed_excel_path = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/renamed_labels.xlsx\"\n",
        "renamed_df.to_excel(renamed_excel_path, index=False)\n",
        "\n",
        "# === Done\n",
        "print(f\"\\n‚úÖ Renamed {len(new_filenames)} images to .png and updated Excel.\")\n",
        "print(f\"‚ö†Ô∏è {len(not_found)} images not found.\")\n",
        "print(f\"üìÅ Renamed images are in: {output_dir}\")\n",
        "print(f\"üìù New Excel is saved at: {renamed_excel_path}\")\n"
      ],
      "metadata": {
        "id": "yU4fDclzLd6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Paths ===\n",
        "input_dir = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/renamed_images\"\n",
        "output_dir = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/resized_denoised_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === Parameters\n",
        "target_size = (200, 200)\n",
        "kernel_size = (3, 3)\n",
        "\n",
        "# === Process images\n",
        "image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "skipped = []\n",
        "\n",
        "for fname in tqdm(image_files, desc=\"Processing images\"):\n",
        "    in_path = os.path.join(input_dir, fname)\n",
        "    out_path = os.path.join(output_dir, fname)\n",
        "\n",
        "    img = cv2.imread(in_path)\n",
        "    if img is None or img.shape[2] != 3:\n",
        "        skipped.append(fname)\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # === Apply Gaussian blur\n",
        "        img = cv2.GaussianBlur(img, kernel_size, 0)\n",
        "\n",
        "        # === Resize to 200x200\n",
        "        img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        # === Normalize to [-1, 1]\n",
        "        normalized = img.astype(np.float32) / 127.5 - 1.0\n",
        "\n",
        "        # === Save back as [0, 255] uint8\n",
        "        out_img = ((normalized + 1.0) * 127.5).astype(np.uint8)\n",
        "        cv2.imwrite(out_path, out_img)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Failed to process {fname}: {e}\")\n",
        "        skipped.append(fname)\n",
        "\n",
        "# === Done\n",
        "print(f\"\\n‚úÖ Done! Processed: {len(image_files) - len(skipped)} images\")\n",
        "print(f\"‚ö†Ô∏è Skipped: {len(skipped)} images\")\n",
        "print(\"üìÅ Output folder:\", output_dir)\n"
      ],
      "metadata": {
        "id": "q9ZuFpjIPX7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# === Folder containing images ===\n",
        "folder_path = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/resized_denoised_images\"\n",
        "\n",
        "# === Loop through all files and check dimensions ===\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.lower().endswith(('.png')):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"‚ùå Could not read {filename}\")\n",
        "            continue\n",
        "\n",
        "        h, w = img.shape[:2]\n",
        "        if h != 200 or w != 200:\n",
        "            print(f\"‚ö†Ô∏è {filename} has size {w}x{h}\")\n"
      ],
      "metadata": {
        "id": "4fqmexprQDOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Paths ===\n",
        "excel_path = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/renamed_labels.xlsx\"\n",
        "image_dir = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/resized_denoised_images\"\n",
        "output_dir = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/resized_denoised_split\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === Load cleaned Excel\n",
        "df = pd.read_excel(excel_path)\n",
        "\n",
        "# === Create subfolders for labels 0 to 4\n",
        "label_counts = {i: 0 for i in range(5)}\n",
        "for i in label_counts:\n",
        "    os.makedirs(os.path.join(output_dir, str(i)), exist_ok=True)\n",
        "\n",
        "# === Split images by label (keep original filenames)\n",
        "for row in tqdm(df.itertuples(index=False), desc=\"Splitting images\"):\n",
        "    fname = row.filename\n",
        "    label = int(row.diagnosis)\n",
        "    src = os.path.join(image_dir, fname)\n",
        "    dst = os.path.join(output_dir, str(label), fname)\n",
        "\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy2(src, dst)\n",
        "        label_counts[label] += 1\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Image not found: {fname}\")\n",
        "\n",
        "# === Show result\n",
        "print(\"\\n‚úÖ Split complete!\")\n",
        "for label in sorted(label_counts):\n",
        "    print(f\"üìÅ Class {label}: {label_counts[label]} images\")\n",
        "print(f\"\\nüîç All images saved in: {output_dir}\")\n"
      ],
      "metadata": {
        "id": "7EUi1c0xQq7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Paths ===\n",
        "input_root = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/resized_denoised_split\"\n",
        "output_root = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/final_split\"\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "ratios = {\"train\": 0.7, \"val\": 0.1, \"test\": 0.2}\n",
        "\n",
        "# === Set up split folders\n",
        "for split in splits:\n",
        "    for label in range(5):\n",
        "        split_path = os.path.join(output_root, split, str(label))\n",
        "        os.makedirs(split_path, exist_ok=True)\n",
        "\n",
        "# === Split each class folder\n",
        "for label in range(5):\n",
        "    class_folder = os.path.join(input_root, str(label))\n",
        "    files = sorted(os.listdir(class_folder))\n",
        "    random.shuffle(files)\n",
        "\n",
        "    n_total = len(files)\n",
        "    n_train = int(ratios[\"train\"] * n_total)\n",
        "    n_val = int(ratios[\"val\"] * n_total)\n",
        "\n",
        "    split_ranges = {\n",
        "        \"train\": files[:n_train],\n",
        "        \"val\": files[n_train:n_train + n_val],\n",
        "        \"test\": files[n_train + n_val:]\n",
        "    }\n",
        "\n",
        "    for split in splits:\n",
        "        for fname in tqdm(split_ranges[split], desc=f\"Copying {split}/{label}\"):\n",
        "            src = os.path.join(class_folder, fname)\n",
        "            dst = os.path.join(output_root, split, str(label), fname)\n",
        "            shutil.copy2(src, dst)\n",
        "\n",
        "# === Done\n",
        "print(\"\\n‚úÖ Final 70/10/20 split complete!\")\n",
        "for split in splits:\n",
        "    for label in range(5):\n",
        "        count = len(os.listdir(os.path.join(output_root, split, str(label))))\n",
        "        print(f\"{split}/{label}: {count} images\")\n"
      ],
      "metadata": {
        "id": "3qsGQYCLQriu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image, ImageEnhance, ImageOps\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === ORIGINAL SPLIT ===\n",
        "original_dir = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/final_split\"\n",
        "target_dir = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/augmented_final_split_fully_balanced\"\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# === Target per class per split\n",
        "target_split = {\n",
        "    \"train\": 7000,\n",
        "    \"val\": 1000,\n",
        "    \"test\": 2000\n",
        "}\n",
        "\n",
        "# === Augmentation methods\n",
        "AUGMENTATIONS = {\n",
        "    'rotate': lambda img: img.rotate(random.uniform(-10, 10)),\n",
        "    'flip_h': lambda img: ImageOps.mirror(img),\n",
        "    'flip_v': lambda img: ImageOps.flip(img),\n",
        "    'zoom': lambda img: img.crop((20, 20, img.width - 20, img.height - 20)).resize((img.width, img.height)),\n",
        "    'brightness': lambda img: ImageEnhance.Brightness(img).enhance(random.uniform(0.5, 1.5)),\n",
        "    'color': lambda img: ImageEnhance.Color(img).enhance(random.uniform(0.5, 1.5)),\n",
        "    'contrast': lambda img: ImageEnhance.Contrast(img).enhance(random.uniform(0.5, 1.5))\n",
        "}\n",
        "\n",
        "def augment_image(img):\n",
        "    aug_img = img.copy()\n",
        "    ops = random.sample(list(AUGMENTATIONS.values()), k=random.randint(3, 5))\n",
        "    for op in ops:\n",
        "        aug_img = op(aug_img)\n",
        "    return aug_img\n",
        "\n",
        "# === Main augmentation loop\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    for label in range(5):\n",
        "        src = os.path.join(original_dir, split, str(label))\n",
        "        dst = os.path.join(target_dir, split, str(label))\n",
        "        os.makedirs(dst, exist_ok=True)\n",
        "\n",
        "        images = sorted(os.listdir(src))\n",
        "        current_count = len(images)\n",
        "        target_count = target_split[split]\n",
        "\n",
        "        # 1. Copy originals\n",
        "        for fname in images:\n",
        "            shutil.copy2(os.path.join(src, fname), os.path.join(dst, fname))\n",
        "\n",
        "        # 2. Augment as needed\n",
        "        if current_count < target_count:\n",
        "            for i in tqdm(range(target_count - current_count), desc=f\"Augmenting {split}/{label}\"):\n",
        "                base_img = random.choice(images)\n",
        "                img = Image.open(os.path.join(src, base_img)).convert(\"RGB\")\n",
        "                aug_img = augment_image(img)\n",
        "                aug_name = f\"aug_{i:05d}_{base_img}\"\n",
        "                aug_img.save(os.path.join(dst, aug_name))\n",
        "\n",
        "print(\"‚úÖ YOU'RE DONEEEE. ALL CLASSES NOW 7k/1k/2k ‚Äî FULLY BALANCED üí™\")\n",
        "\n",
        "# === COUNTING IMAGES IN EACH FOLDER ===\n",
        "print(\"\\nüìä FINAL IMAGE COUNTS PER FOLDER:\\n\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    for label in range(5):\n",
        "        folder = os.path.join(target_dir, split, str(label))\n",
        "        count = len(os.listdir(folder))\n",
        "        print(f\"{split}/{label}: {count} images\")\n"
      ],
      "metadata": {
        "id": "0HJNex8ERNif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Folder containing oversized class 0 folders\n",
        "class0_paths = {\n",
        "    \"train\": \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/augmented_final_split_fully_balanced/train/0\",\n",
        "    \"val\":   \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/augmented_final_split_fully_balanced/val/0\",\n",
        "    \"test\":  \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/augmented_final_split_fully_balanced/test/0\"\n",
        "}\n",
        "\n",
        "# === Desired count per split\n",
        "target_counts = {\n",
        "    \"train\": 7000,\n",
        "    \"val\": 1000,\n",
        "    \"test\": 2000\n",
        "}\n",
        "\n",
        "# === Delete excess images\n",
        "for split, path in class0_paths.items():\n",
        "    all_files = sorted(os.listdir(path))\n",
        "    target = target_counts[split]\n",
        "\n",
        "    if len(all_files) > target:\n",
        "        to_delete = random.sample(all_files, len(all_files) - target)\n",
        "        for fname in tqdm(to_delete, desc=f\"Deleting from {split}/0\"):\n",
        "            os.remove(os.path.join(path, fname))\n",
        "\n",
        "print(\"\\nüóëÔ∏è DONE! Class 0 is now cleanly trimmed to 7k/1k/2k. BALANCE ACHIEVED ‚öñÔ∏è\")\n"
      ],
      "metadata": {
        "id": "Xkm7AZrzbUtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === COUNTING IMAGES IN EACH FOLDER ===\n",
        "print(\"\\nüìä FINAL IMAGE COUNTS PER FOLDER:\\n\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    for label in range(5):\n",
        "        folder = os.path.join(target_dir, split, str(label))\n",
        "        count = len(os.listdir(folder))\n",
        "        print(f\"{split}/{label}: {count} images\")\n"
      ],
      "metadata": {
        "id": "86O3Onhebflx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "\n",
        "# Paths (YOUR setup)\n",
        "src_base = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/augmented_final_split_fully_balanced\"\n",
        "dst_base = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/augmented_final_split_binary\"\n",
        "\n",
        "# Splits and classes\n",
        "splits = ['train', 'val', 'test']\n",
        "classes = ['0', '1', '2', '3', '4']\n",
        "\n",
        "# Make folders for binary split (0 vs 1)\n",
        "for split in splits:\n",
        "    os.makedirs(os.path.join(dst_base, split, '0'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(dst_base, split, '1'), exist_ok=True)  # 1 for merged 1-4\n",
        "\n",
        "# Copy files over and merge classes 1-4 into '1'\n",
        "for split in splits:\n",
        "    for cls in classes:\n",
        "        src_dir = os.path.join(src_base, split, cls)\n",
        "        dst_dir = os.path.join(dst_base, split, '0' if cls == '0' else '1')\n",
        "        if os.path.exists(src_dir):\n",
        "            for fname in os.listdir(src_dir):\n",
        "                shutil.copy2(os.path.join(src_dir, fname), os.path.join(dst_dir, fname))\n",
        "\n",
        "# Count images in each binary class folder\n",
        "from collections import defaultdict\n",
        "counts = defaultdict(int)\n",
        "for split in splits:\n",
        "    for cls in ['0', '1']:\n",
        "        folder = os.path.join(dst_base, split, cls)\n",
        "        counts[(split, cls)] = len(os.listdir(folder))\n",
        "\n",
        "# Display counts\n",
        "import pandas as pd\n",
        "df = pd.DataFrame([{'Split': split, 'Class': cls, 'Count': count} for (split, cls), count in counts.items()])\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "Yg8sh834_Gxc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
