{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3btje0_Vt1LI",
        "outputId": "f08c6a84-5469-4b69-dfa2-a74eeb61158e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Paths ===\n",
        "image_folders = [\n",
        "    \"/content/drive/MyDrive/EECE 490 Project/EyePac/Cleaned_images\",\n",
        "    \"/content/drive/MyDrive/EECE 490 Project/DDR dataset/Cleaned_DDR\",\n",
        "    \"/content/drive/MyDrive/EECE 490 Project/Aptos/train_images_cleaned\",\n",
        "    \"/content/drive/MyDrive/EECE 490 Project/IDRD/Cleaned_IDRiD\"\n",
        "]\n",
        "\n",
        "combined_image_folder = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/All_Images\"\n",
        "os.makedirs(combined_image_folder, exist_ok=True)\n",
        "\n",
        "# === Combine Images ===\n",
        "for folder in image_folders:\n",
        "    for file in os.listdir(folder):\n",
        "        src = os.path.join(folder, file)\n",
        "        dst = os.path.join(combined_image_folder, file)\n",
        "        if os.path.isfile(src):\n",
        "            shutil.copy2(src, dst)\n",
        "\n",
        "print(\"‚úÖ All images copied to:\", combined_image_folder)"
      ],
      "metadata": {
        "id": "AqrjxJHon80e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# === Excel Files to Combine ===\n",
        "excel_paths = [\n",
        "    \"/content/drive/MyDrive/EECE 490 Project/EyePac/trainLabels_filtered.xlsx\",\n",
        "    \"/content/drive/MyDrive/EECE 490 Project/DDR dataset/DR_grading_cleaned.xlsx\",\n",
        "    \"/content/drive/MyDrive/EECE 490 Project/Aptos/train_cleaned.xlsx\",\n",
        "    \"/content/drive/MyDrive/EECE 490 Project/IDRD/cleaned_labels.xlsx\",\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for path in excel_paths:\n",
        "    df = pd.read_excel(path)\n",
        "    if \"filename\" in df.columns and \"diagnosis\" in df.columns:\n",
        "        dfs.append(df[[\"filename\", \"diagnosis\"]])\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Columns missing in: {path}\")\n",
        "\n",
        "# === Merge and Save ===\n",
        "combined_df = pd.concat(dfs, ignore_index=True)\n",
        "combined_excel_path = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/combined_labels.xlsx\"\n",
        "combined_df.to_excel(combined_excel_path, index=False)\n",
        "\n",
        "print(\"‚úÖ Combined Excel saved at:\", combined_excel_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjCdBDe9t1SG",
        "outputId": "0efa6519-3ab7-4ff1-bcd5-111fd19e8cd5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Combined Excel saved at: /content/drive/MyDrive/EECE 490 Project/Classification_Set/combined_labels.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Count number of images in folder ===\n",
        "num_images = len(os.listdir(\"/content/drive/MyDrive/EECE 490 Project/Classification_Set/All_Images\"))\n",
        "\n",
        "# === Count number of rows in Excel ===\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/EECE 490 Project/Classification_Set/combined_labels.xlsx\")\n",
        "num_labels = len(df)\n",
        "\n",
        "# === Print results ===\n",
        "print(f\"üñºÔ∏è Total images in folder: {num_images}\")\n",
        "print(f\"üìÑ Total labels in Excel:  {num_labels}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij0-6m8UpBjM",
        "outputId": "de637a14-b8dd-4a91-f44b-82811537fa3b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üñºÔ∏è Total images in folder: 37480\n",
            "üìÑ Total labels in Excel:  37479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm  # <--- progress bar\n",
        "\n",
        "# === Paths ===\n",
        "combined_excel_path = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/combined_labels.xlsx\"\n",
        "image_dir = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/All_Images\"\n",
        "output_dir = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/renamed_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === Load Excel\n",
        "df = pd.read_excel(combined_excel_path)\n",
        "\n",
        "# === Prepare new list\n",
        "new_filenames = []\n",
        "preserved_diagnoses = []\n",
        "image_counter = 1\n",
        "not_found = []\n",
        "\n",
        "# === Loop through Excel with tqdm\n",
        "for row in tqdm(df.itertuples(index=False), total=len(df), desc=\"Processing\"):\n",
        "    original_name = os.path.splitext(str(row.filename))[0]\n",
        "    label = row.diagnosis\n",
        "    found = False\n",
        "\n",
        "    for ext in ['.jpeg', '.jpg', '.JPG', '.JPEG']:\n",
        "        image_path = os.path.join(image_dir, original_name + ext)\n",
        "        if os.path.exists(image_path):\n",
        "            new_filename = f\"img_{image_counter:05d}.png\"\n",
        "            img = Image.open(image_path).convert(\"RGB\")\n",
        "            img.save(os.path.join(output_dir, new_filename))\n",
        "\n",
        "            new_filenames.append(new_filename)\n",
        "            preserved_diagnoses.append(label)\n",
        "            image_counter += 1\n",
        "            found = True\n",
        "            break\n",
        "\n",
        "    if not found:\n",
        "        not_found.append(original_name)\n",
        "\n",
        "# === Save updated Excel\n",
        "renamed_df = pd.DataFrame({\n",
        "    \"filename\": new_filenames,\n",
        "    \"diagnosis\": preserved_diagnoses\n",
        "})\n",
        "renamed_excel_path = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/renamed_labels.xlsx\"\n",
        "renamed_df.to_excel(renamed_excel_path, index=False)\n",
        "\n",
        "# === Done\n",
        "print(f\"\\n‚úÖ Renamed {len(new_filenames)} images to .png and updated Excel.\")\n",
        "print(f\"‚ö†Ô∏è {len(not_found)} images not found.\")\n",
        "print(f\"üìÅ Renamed images are in: {output_dir}\")\n",
        "print(f\"üìù New Excel is saved at: {renamed_excel_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU4fDclzLd6u",
        "outputId": "2351987a-d977-48c4-c7ee-7116a47c261b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37479/37479 [1:31:45<00:00,  6.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Renamed 37475 images to .png and updated Excel.\n",
            "‚ö†Ô∏è 4 images not found.\n",
            "üìÅ Renamed images are in: /content/drive/MyDrive/EECE 490 Project/Classification_Set/renamed_images\n",
            "üìù New Excel is saved at: /content/drive/MyDrive/EECE 490 Project/Classification_Set/renamed_labels.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Paths ===\n",
        "input_dir = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/renamed_images\"\n",
        "output_dir = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/resized_denoised_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === Parameters\n",
        "target_size = (200, 200)\n",
        "kernel_size = (3, 3)\n",
        "\n",
        "# === Process images\n",
        "image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "skipped = []\n",
        "\n",
        "for fname in tqdm(image_files, desc=\"Processing images\"):\n",
        "    in_path = os.path.join(input_dir, fname)\n",
        "    out_path = os.path.join(output_dir, fname)\n",
        "\n",
        "    img = cv2.imread(in_path)\n",
        "    if img is None or img.shape[2] != 3:\n",
        "        skipped.append(fname)\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # === Apply Gaussian blur\n",
        "        img = cv2.GaussianBlur(img, kernel_size, 0)\n",
        "\n",
        "        # === Resize to 200x200\n",
        "        img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        # === Normalize to [-1, 1]\n",
        "        normalized = img.astype(np.float32) / 127.5 - 1.0\n",
        "\n",
        "        # === Save back as [0, 255] uint8\n",
        "        out_img = ((normalized + 1.0) * 127.5).astype(np.uint8)\n",
        "        cv2.imwrite(out_path, out_img)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Failed to process {fname}: {e}\")\n",
        "        skipped.append(fname)\n",
        "\n",
        "# === Done\n",
        "print(f\"\\n‚úÖ Done! Processed: {len(image_files) - len(skipped)} images\")\n",
        "print(f\"‚ö†Ô∏è Skipped: {len(skipped)} images\")\n",
        "print(\"üìÅ Output folder:\", output_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9ZuFpjIPX7c",
        "outputId": "e9b482c1-ba5e-4ad4-a043-bfcf026afc5e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37475/37475 [36:02<00:00, 17.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Done! Processed: 37475 images\n",
            "‚ö†Ô∏è Skipped: 0 images\n",
            "üìÅ Output folder: /content/drive/MyDrive/EECE 490 Project/Classification_Set/resized_denoised_images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# === Folder containing images ===\n",
        "folder_path = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/resized_denoised_images\"\n",
        "\n",
        "# === Loop through all files and check dimensions ===\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.lower().endswith(('.png')):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"‚ùå Could not read {filename}\")\n",
        "            continue\n",
        "\n",
        "        h, w = img.shape[:2]\n",
        "        if h != 200 or w != 200:\n",
        "            print(f\"‚ö†Ô∏è {filename} has size {w}x{h}\")\n"
      ],
      "metadata": {
        "id": "4fqmexprQDOg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Paths ===\n",
        "excel_path = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/renamed_labels.xlsx\"\n",
        "image_dir = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/resized_denoised_images\"\n",
        "output_dir = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/resized_denoised_split\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === Load cleaned Excel\n",
        "df = pd.read_excel(excel_path)\n",
        "\n",
        "# === Create subfolders for labels 0 to 4\n",
        "label_counts = {i: 0 for i in range(5)}\n",
        "for i in label_counts:\n",
        "    os.makedirs(os.path.join(output_dir, str(i)), exist_ok=True)\n",
        "\n",
        "# === Split images by label (keep original filenames)\n",
        "for row in tqdm(df.itertuples(index=False), desc=\"Splitting images\"):\n",
        "    fname = row.filename\n",
        "    label = int(row.diagnosis)\n",
        "    src = os.path.join(image_dir, fname)\n",
        "    dst = os.path.join(output_dir, str(label), fname)\n",
        "\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy2(src, dst)\n",
        "        label_counts[label] += 1\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Image not found: {fname}\")\n",
        "\n",
        "# === Show result\n",
        "print(\"\\n‚úÖ Split complete!\")\n",
        "for label in sorted(label_counts):\n",
        "    print(f\"üìÅ Class {label}: {label_counts[label]} images\")\n",
        "print(f\"\\nüîç All images saved in: {output_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EUi1c0xQq7U",
        "outputId": "fa4b6b1c-ef16-487d-8317-a715a295954d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Splitting images: 37475it [11:26, 54.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Split complete!\n",
            "üìÅ Class 0: 25140 images\n",
            "üìÅ Class 1: 2453 images\n",
            "üìÅ Class 2: 7817 images\n",
            "üìÅ Class 3: 913 images\n",
            "üìÅ Class 4: 1152 images\n",
            "\n",
            "üîç All images saved in: /content/drive/MyDrive/EECE 490 Project/Classification_Set/resized_denoised_split\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Paths ===\n",
        "input_root = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/resized_denoised_split\"\n",
        "output_root = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/final_split\"\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "ratios = {\"train\": 0.7, \"val\": 0.1, \"test\": 0.2}\n",
        "\n",
        "# === Set up split folders\n",
        "for split in splits:\n",
        "    for label in range(5):\n",
        "        split_path = os.path.join(output_root, split, str(label))\n",
        "        os.makedirs(split_path, exist_ok=True)\n",
        "\n",
        "# === Split each class folder\n",
        "for label in range(5):\n",
        "    class_folder = os.path.join(input_root, str(label))\n",
        "    files = sorted(os.listdir(class_folder))\n",
        "    random.shuffle(files)\n",
        "\n",
        "    n_total = len(files)\n",
        "    n_train = int(ratios[\"train\"] * n_total)\n",
        "    n_val = int(ratios[\"val\"] * n_total)\n",
        "\n",
        "    split_ranges = {\n",
        "        \"train\": files[:n_train],\n",
        "        \"val\": files[n_train:n_train + n_val],\n",
        "        \"test\": files[n_train + n_val:]\n",
        "    }\n",
        "\n",
        "    for split in splits:\n",
        "        for fname in tqdm(split_ranges[split], desc=f\"Copying {split}/{label}\"):\n",
        "            src = os.path.join(class_folder, fname)\n",
        "            dst = os.path.join(output_root, split, str(label), fname)\n",
        "            shutil.copy2(src, dst)\n",
        "\n",
        "# === Done\n",
        "print(\"\\n‚úÖ Final 70/10/20 split complete!\")\n",
        "for split in splits:\n",
        "    for label in range(5):\n",
        "        count = len(os.listdir(os.path.join(output_root, split, str(label))))\n",
        "        print(f\"{split}/{label}: {count} images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qsGQYCLQriu",
        "outputId": "82171057-8987-42b6-a63f-30a9b5e03981"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying train/0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17598/17598 [13:14<00:00, 22.15it/s]\n",
            "Copying val/0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2514/2514 [00:47<00:00, 53.34it/s]\n",
            "Copying test/0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5028/5028 [01:36<00:00, 52.16it/s]\n",
            "Copying train/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1717/1717 [01:12<00:00, 23.54it/s]\n",
            "Copying val/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:04<00:00, 56.12it/s]\n",
            "Copying test/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 491/491 [00:08<00:00, 55.58it/s]\n",
            "Copying train/2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5471/5471 [04:20<00:00, 21.00it/s]\n",
            "Copying val/2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781/781 [00:14<00:00, 55.65it/s]\n",
            "Copying test/2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1565/1565 [00:29<00:00, 53.54it/s]\n",
            "Copying train/3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 639/639 [00:17<00:00, 36.29it/s]\n",
            "Copying val/3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91/91 [00:02<00:00, 40.65it/s]\n",
            "Copying test/3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 183/183 [00:02<00:00, 61.35it/s]\n",
            "Copying train/4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 806/806 [00:24<00:00, 32.98it/s]\n",
            "Copying val/4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 115/115 [00:02<00:00, 51.43it/s]\n",
            "Copying test/4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 231/231 [00:07<00:00, 30.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Final 70/10/20 split complete!\n",
            "train/0: 17598 images\n",
            "train/1: 1717 images\n",
            "train/2: 5471 images\n",
            "train/3: 639 images\n",
            "train/4: 806 images\n",
            "val/0: 2514 images\n",
            "val/1: 245 images\n",
            "val/2: 781 images\n",
            "val/3: 91 images\n",
            "val/4: 115 images\n",
            "test/0: 5028 images\n",
            "test/1: 491 images\n",
            "test/2: 1565 images\n",
            "test/3: 183 images\n",
            "test/4: 231 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image, ImageEnhance, ImageOps\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === ORIGINAL SPLIT ===\n",
        "original_dir = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/final_split\"\n",
        "target_dir = \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/augmented_final_split_fully_balanced\"\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# === Target per class per split\n",
        "target_split = {\n",
        "    \"train\": 7000,\n",
        "    \"val\": 1000,\n",
        "    \"test\": 2000\n",
        "}\n",
        "\n",
        "# === Augmentation methods\n",
        "AUGMENTATIONS = {\n",
        "    'rotate': lambda img: img.rotate(random.uniform(-10, 10)),\n",
        "    'flip_h': lambda img: ImageOps.mirror(img),\n",
        "    'flip_v': lambda img: ImageOps.flip(img),\n",
        "    'zoom': lambda img: img.crop((20, 20, img.width - 20, img.height - 20)).resize((img.width, img.height)),\n",
        "    'brightness': lambda img: ImageEnhance.Brightness(img).enhance(random.uniform(0.5, 1.5)),\n",
        "    'color': lambda img: ImageEnhance.Color(img).enhance(random.uniform(0.5, 1.5)),\n",
        "    'contrast': lambda img: ImageEnhance.Contrast(img).enhance(random.uniform(0.5, 1.5))\n",
        "}\n",
        "\n",
        "def augment_image(img):\n",
        "    aug_img = img.copy()\n",
        "    ops = random.sample(list(AUGMENTATIONS.values()), k=random.randint(3, 5))\n",
        "    for op in ops:\n",
        "        aug_img = op(aug_img)\n",
        "    return aug_img\n",
        "\n",
        "# === Main augmentation loop\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    for label in range(5):\n",
        "        src = os.path.join(original_dir, split, str(label))\n",
        "        dst = os.path.join(target_dir, split, str(label))\n",
        "        os.makedirs(dst, exist_ok=True)\n",
        "\n",
        "        images = sorted(os.listdir(src))\n",
        "        current_count = len(images)\n",
        "        target_count = target_split[split]\n",
        "\n",
        "        # 1. Copy originals\n",
        "        for fname in images:\n",
        "            shutil.copy2(os.path.join(src, fname), os.path.join(dst, fname))\n",
        "\n",
        "        # 2. Augment as needed\n",
        "        if current_count < target_count:\n",
        "            for i in tqdm(range(target_count - current_count), desc=f\"Augmenting {split}/{label}\"):\n",
        "                base_img = random.choice(images)\n",
        "                img = Image.open(os.path.join(src, base_img)).convert(\"RGB\")\n",
        "                aug_img = augment_image(img)\n",
        "                aug_name = f\"aug_{i:05d}_{base_img}\"\n",
        "                aug_img.save(os.path.join(dst, aug_name))\n",
        "\n",
        "print(\"‚úÖ YOU'RE DONEEEE. ALL CLASSES NOW 7k/1k/2k ‚Äî FULLY BALANCED üí™\")\n",
        "\n",
        "# === COUNTING IMAGES IN EACH FOLDER ===\n",
        "print(\"\\nüìä FINAL IMAGE COUNTS PER FOLDER:\\n\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    for label in range(5):\n",
        "        folder = os.path.join(target_dir, split, str(label))\n",
        "        count = len(os.listdir(folder))\n",
        "        print(f\"{split}/{label}: {count} images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HJNex8ERNif",
        "outputId": "d1a58b66-1490-4fe7-aff0-8175d07f7e00"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting train/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5283/5283 [03:49<00:00, 23.04it/s]\n",
            "Augmenting train/2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1529/1529 [01:09<00:00, 21.91it/s]\n",
            "Augmenting train/3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6361/6361 [04:47<00:00, 22.15it/s]\n",
            "Augmenting train/4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6194/6194 [04:43<00:00, 21.81it/s]\n",
            "Augmenting val/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755/755 [00:31<00:00, 23.65it/s]\n",
            "Augmenting val/2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:09<00:00, 22.09it/s]\n",
            "Augmenting val/3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 909/909 [00:37<00:00, 24.05it/s]\n",
            "Augmenting val/4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 885/885 [00:37<00:00, 23.49it/s]\n",
            "Augmenting test/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1509/1509 [01:04<00:00, 23.39it/s]\n",
            "Augmenting test/2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 435/435 [00:19<00:00, 22.55it/s]\n",
            "Augmenting test/3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1817/1817 [01:18<00:00, 23.29it/s]\n",
            "Augmenting test/4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1769/1769 [01:19<00:00, 22.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ YOU'RE DONEEEE. ALL CLASSES NOW 7k/1k/2k ‚Äî FULLY BALANCED üí™\n",
            "\n",
            "üìä FINAL IMAGE COUNTS PER FOLDER:\n",
            "\n",
            "train/0: 17598 images\n",
            "train/1: 7000 images\n",
            "train/2: 7000 images\n",
            "train/3: 7000 images\n",
            "train/4: 7000 images\n",
            "val/0: 2514 images\n",
            "val/1: 1000 images\n",
            "val/2: 1000 images\n",
            "val/3: 1000 images\n",
            "val/4: 1000 images\n",
            "test/0: 5028 images\n",
            "test/1: 2000 images\n",
            "test/2: 2000 images\n",
            "test/3: 2000 images\n",
            "test/4: 2000 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Folder containing oversized class 0 folders\n",
        "class0_paths = {\n",
        "    \"train\": \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/augmented_final_split_fully_balanced/train/0\",\n",
        "    \"val\":   \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/augmented_final_split_fully_balanced/val/0\",\n",
        "    \"test\":  \"/content/drive/MyDrive/EECE 490 Project/Classification_Set/augmented_final_split_fully_balanced/test/0\"\n",
        "}\n",
        "\n",
        "# === Desired count per split\n",
        "target_counts = {\n",
        "    \"train\": 7000,\n",
        "    \"val\": 1000,\n",
        "    \"test\": 2000\n",
        "}\n",
        "\n",
        "# === Delete excess images\n",
        "for split, path in class0_paths.items():\n",
        "    all_files = sorted(os.listdir(path))\n",
        "    target = target_counts[split]\n",
        "\n",
        "    if len(all_files) > target:\n",
        "        to_delete = random.sample(all_files, len(all_files) - target)\n",
        "        for fname in tqdm(to_delete, desc=f\"Deleting from {split}/0\"):\n",
        "            os.remove(os.path.join(path, fname))\n",
        "\n",
        "print(\"\\nüóëÔ∏è DONE! Class 0 is now cleanly trimmed to 7k/1k/2k. BALANCE ACHIEVED ‚öñÔ∏è\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xkm7AZrzbUtN",
        "outputId": "9eb46f3a-39ab-4015-b8c1-8e07414abb09"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Deleting from train/0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10598/10598 [00:36<00:00, 294.30it/s]\n",
            "Deleting from val/0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1514/1514 [00:05<00:00, 297.06it/s]\n",
            "Deleting from test/0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3028/3028 [00:09<00:00, 312.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üóëÔ∏è DONE! Class 0 is now cleanly trimmed to 7k/1k/2k. BALANCE ACHIEVED ‚öñÔ∏è\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === COUNTING IMAGES IN EACH FOLDER ===\n",
        "print(\"\\nüìä FINAL IMAGE COUNTS PER FOLDER:\\n\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    for label in range(5):\n",
        "        folder = os.path.join(target_dir, split, str(label))\n",
        "        count = len(os.listdir(folder))\n",
        "        print(f\"{split}/{label}: {count} images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86O3Onhebflx",
        "outputId": "323c4c4f-74b7-4030-b1da-535041b39131"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä FINAL IMAGE COUNTS PER FOLDER:\n",
            "\n",
            "train/0: 7000 images\n",
            "train/1: 7000 images\n",
            "train/2: 7000 images\n",
            "train/3: 7000 images\n",
            "train/4: 7000 images\n",
            "val/0: 1000 images\n",
            "val/1: 1000 images\n",
            "val/2: 1000 images\n",
            "val/3: 1000 images\n",
            "val/4: 1000 images\n",
            "test/0: 2000 images\n",
            "test/1: 2000 images\n",
            "test/2: 2000 images\n",
            "test/3: 2000 images\n",
            "test/4: 2000 images\n"
          ]
        }
      ]
    }
  ]
}