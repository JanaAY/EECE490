{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install flask flask-ngrok flask-cors --quiet\n"],"metadata":{"id":"_qjJYKvg1d_l","executionInfo":{"status":"ok","timestamp":1745233486439,"user_tz":-180,"elapsed":14000,"user":{"displayName":"Jana Ayoub","userId":"03185760549039688687"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OVKLnUMUH_iO","executionInfo":{"status":"ok","timestamp":1745233512807,"user_tz":-180,"elapsed":26371,"user":{"displayName":"Jana Ayoub","userId":"03185760549039688687"}},"outputId":"04d22206-0883-4d0e-a439-def3111fcecc"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install --quiet langchain openai tiktoken faiss-cpu PyMuPDF\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59DXetSoIakK","executionInfo":{"status":"ok","timestamp":1745233532740,"user_tz":-180,"elapsed":19931,"user":{"displayName":"Jana Ayoub","userId":"03185760549039688687"}},"outputId":"d16d109b-1fcf-4ffb-f9a4-3bf7718e3b27"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Install Git (usually pre-installed)\n","!apt-get install git -y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NjD8RY6ARp_-","outputId":"ea705a41-4556-4070-e1c8-7c642b911c75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[]}]},{"cell_type":"code","source":["%cd /content\n","!rm -rf EECE490\n"],"metadata":{"id":"99eryMPkRuCL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://TiaTarabay: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@github.com/JanaAY/EECE490.git\n","%cd EECE490\n"],"metadata":{"id":"LRSOlYVqRwPY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mv \"/content/drive/MyDrive/Colab Notebooks/Finetuned_Chatbot.ipynb\" .\n"],"metadata":{"id":"FP6r2MorR0Fy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git config user.name \"TiaTarabay\"\n","!git config user.email \"twt00@mail.aub.edu\"\n","\n","!git add \"Finetuned_Chatbot.ipynb\"\n","!git commit -m \"Add finetuned chatbot\"\n","!git push\n"],"metadata":{"id":"6CPFFLzOSDln"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Clean start\n","%cd /content\n","!rm -rf EECE490\n","\n","# Clone fresh\n","!git clone https://TiaTarabay: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@github.com/JanaAY/EECE490.git\n","%cd EECE490\n","\n","# Set identity (IMPORTANT: after cd into EECE490)\n","!git config user.name \"TiaTarabay\"\n","!git config user.email \"twt00@mail.aub.edu\"\n","\n","# Delete the nested EECE490 folder\n","!rm -rf EECE490\n","\n","# Stage, commit, push\n","!git add .\n","!git commit -m \"Remove nested EECE490 folder\"\n","!git push\n"],"metadata":{"id":"XaxJHCw0Wv43"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pypdf\n","!pip install -U langchain-community\n","\n","from langchain_community.document_loaders import PyPDFLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_core.documents import Document\n","import os\n","\n","# Folder where PDFs are stored\n","pdf_dir = \"/content/drive/MyDrive/newarticles\"\n","\n","# Load and split\n","documents = []\n","splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n","\n","for filename in os.listdir(pdf_dir):\n","    if filename.endswith(\".pdf\"):\n","        loader = PyPDFLoader(os.path.join(pdf_dir, filename))\n","        docs = loader.load()\n","        chunks = splitter.split_documents(docs)\n","        documents.extend(chunks)\n","\n","print(f\"Loaded and split {len(documents)} chunks.\")\n"],"metadata":{"id":"aKnCbob9JKBb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from openai import AzureOpenAI\n","\n","client = AzureOpenAI(\n","    azure_endpoint=\"https://twt00-m9jvr359-eastus2.openai.azure.com/\",\n","    api_key=\"CIOd5mdimXIfdjcMJ8ZqfmUAwSJPGQuxzogAgD8HsKYu4NBcRQoCJQQJ99BDACHYHv6XJ3w3AAAAACOG9VXo\",\n","    api_version=\"2025-01-01-preview\"\n",")\n","\n","response = client.embeddings.create(\n","    model=\"text-embedding-ada-002\",  # must match deployment name\n","    input=[\"Test sentence about diabetic retinopathy.\"]\n",")\n","\n","print(response.data[0].embedding[:5])\n"],"metadata":{"id":"GJlhW49fJj0L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from openai import AzureOpenAI\n","import numpy as np\n","import faiss\n","\n","# Azure config\n","client = AzureOpenAI(\n","    api_key=\"CIOd5mdimXIfdjcMJ8ZqfmUAwSJPGQuxzogAgD8HsKYu4NBcRQoCJQQJ99BDACHYHv6XJ3w3AAAAACOG9VXo\",\n","    azure_endpoint=\"https://twt00-m9jvr359-eastus2.openai.azure.com/\",\n","    api_version=\"2025-01-01-preview\"\n",")\n","\n","# Chunk texts\n","texts = [doc.page_content for doc in documents]\n","\n","# Embed\n","embeddings = []\n","for text in texts:\n","    response = client.embeddings.create(\n","        model=\"text-embedding-ada-002\",  # This is your Azure *deployment name*\n","        input=[text]\n","    )\n","    vector = response.data[0].embedding\n","    embeddings.append(vector)\n","\n","embedding_matrix = np.array(embeddings).astype(\"float32\")\n"],"metadata":{"id":"ekphMVSSLB7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","dimension = embedding_matrix.shape[1]\n","index = faiss.IndexFlatL2(dimension)\n","index.add(embedding_matrix)\n","\n","# Save index and metadata\n","faiss.write_index(index, \"dr_index.faiss\")\n","\n","with open(\"dr_texts.pkl\", \"wb\") as f:\n","    pickle.dump(texts, f)\n","\n","print(\"FAISS index and texts saved.\")\n"],"metadata":{"id":"i8WUPykrOMG4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import faiss\n","import pickle\n","from openai import AzureOpenAI\n","\n","# === Load FAISS + text chunks ===\n","index = faiss.read_index(\"dr_index.faiss\")\n","\n","with open(\"dr_texts.pkl\", \"rb\") as f:\n","    texts = pickle.load(f)\n","\n","# === Initialize Azure OpenAI client ===\n","client = AzureOpenAI(\n","    azure_endpoint=\"https://twt00-m9jvr359-eastus2.openai.azure.com/\",\n","    api_key=\"CIOd5mdimXIfdjcMJ8ZqfmUAwSJPGQuxzogAgD8HsKYu4NBcRQoCJQQJ99BDACHYHv6XJ3w3AAAAACOG9VXo\",\n","    api_version=\"2025-01-01-preview\"\n",")\n","\n","# === Function to embed user query ===\n","def embed_query(text):\n","    response = client.embeddings.create(\n","        model=\"text-embedding-ada-002\",\n","        input=[text]\n","    )\n","    return np.array(response.data[0].embedding).astype(\"float32\").reshape(1, -1)\n","\n","# === Hybrid chatbot ===\n","def ask_gpt_with_context(query, top_k=3):\n","    # 1. Embed query\n","    query_vec = embed_query(query)\n","\n","    # 2. Search FAISS\n","    scores, indices = index.search(query_vec, top_k)\n","    retrieved_chunks = [texts[i] for i in indices[0]]\n","\n","    # 3. Build prompt\n","    context = \"\\n\\n\".join(retrieved_chunks)\n","    messages = [\n","      {\n","          \"role\": \"system\",\n","          \"content\": (\n","              \"You are a friendly and helpful assistant specialized in diabetic retinopathy (DR). \"\n","              \"Always greet users warmly and answer in a clear, supportive tone. \"\n","              \"Only answer questions related to diabetic retinopathy. \"\n","              \"If a question is unrelated, respond politely with: \"\n","              \"'I'm sorry, I only provide support for diabetic retinopathy-related topics.'\\n\\n\"\n","              \"Use the following research document context if helpful:\\n\\n\" + context\n","          )\n","      },\n","      {\"role\": \"user\", \"content\": query}\n","  ]\n","\n","\n","    # 4. Call GPT\n","    response = client.chat.completions.create(\n","        model=\"gpt-4o-mini\",  # your Azure chat deployment\n","        messages=messages,\n","        max_tokens=800,\n","        temperature=0.5\n","    )\n","\n","    return response.choices[0].message.content\n"],"metadata":{"id":"xSJgY1JdOU35"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(ask_gpt_with_context(\"What is the role of the green channel in DR detection?\"))\n"],"metadata":{"id":"zMJSeuITOoOZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","def clean_query(text):\n","    # Basic cleanup: remove extra spaces, fix common OCR artifacts, lowercase\n","    text = text.lower()\n","    text = re.sub(r\"\\s+\", \" \", text)\n","    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n","    return text.strip()\n"],"metadata":{"id":"yncW7enfPTlq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","import faiss\n","import pickle\n","import numpy as np\n","from openai import AzureOpenAI\n","\n","# === Load FAISS and texts ===\n","index = faiss.read_index(\"dr_index.faiss\")\n","with open(\"dr_texts.pkl\", \"rb\") as f:\n","    texts = pickle.load(f)\n","\n","# === Azure OpenAI client ===\n","client = AzureOpenAI(\n","    azure_endpoint=\"https://twt00-m9jvr359-eastus2.openai.azure.com/\",\n","    api_key=\"CIOd5mdimXIfdjcMJ8ZqfmUAwSJPGQuxzogAgD8HsKYu4NBcRQoCJQQJ99BDACHYHv6XJ3w3AAAAACOG9VXo\",\n","    api_version=\"2025-01-01-preview\"\n",")\n","\n","# === Clean query to handle typos ===\n","def clean_query(text):\n","    text = text.lower()\n","    text = re.sub(r\"\\s+\", \" \", text)\n","    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n","    return text.strip()\n","\n","# === Embed query using Azure ===\n","def embed_query(text):\n","    response = client.embeddings.create(\n","        model=\"text-embedding-ada-002\",  # your deployment name\n","        input=[text]\n","    )\n","    return np.array(response.data[0].embedding).astype(\"float32\").reshape(1, -1)\n","\n","# === Chatbot function ===\n","def ask_gpt_with_context(query, top_k=3):\n","    query_clean = clean_query(query)  # ‚úÖ this line is now valid\n","    query_vec = embed_query(query_clean)\n","\n","    scores, indices = index.search(query_vec, top_k)\n","    retrieved_chunks = [texts[i] for i in indices[0]]\n","    context = \"\\n\\n\".join(retrieved_chunks)\n","\n","    messages = [\n","        {\n","            \"role\": \"system\",\n","            \"content\": (\n","                \"You are a friendly and helpful assistant specialized in diabetic retinopathy. \"\n","                \"Only answer questions related to diabetic retinopathy. \"\n","                \"If a question is unrelated, say: 'I'm sorry, I only provide support for diabetic retinopathy-related topics.'\\n\\n\"\n","                \"Use the following research context if relevant:\\n\\n\" + context\n","            )\n","        },\n","        {\"role\": \"user\", \"content\": query}\n","    ]\n","\n","    response = client.chat.completions.create(\n","        model=\"gpt-4o-mini\",\n","        messages=messages,\n","        max_tokens=800,\n","        temperature=0.5\n","    )\n","\n","    return response.choices[0].message.content\n"],"metadata":{"id":"N5a6tOEePriM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(ask_gpt_with_context(\"what are symtoms of diebetic retinpathy\"))\n"],"metadata":{"id":"gW38BODTPtUb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ask_gpt_with_context(query, top_k=3):\n","    query_clean = clean_query(query)\n","    query_vec = embed_query(query_clean)\n","\n","    scores, indices = index.search(query_vec, top_k)\n","    retrieved_chunks = [texts[i] for i in indices[0]]\n","    context = \"\\n\\n\".join(retrieved_chunks)\n","\n","    # üìé Source references (chunk numbers)\n","    source_info = \"\\n\\nSources:\\n\" + \"\\n\".join([f\"- Chunk {i+1}\" for i in indices[0]])\n","\n","    messages = [\n","        {\n","            \"role\": \"system\",\n","            \"content\": (\n","                \"You are a friendly and helpful assistant specialized in diabetic retinopathy. \"\n","                \"Only answer DR-related questions. Use the following document context if helpful:\\n\\n\" + context\n","            )\n","        },\n","        {\n","            \"role\": \"user\",\n","            \"content\": query + source_info  # Include sources in the question content\n","        }\n","    ]\n","\n","    response = client.chat.completions.create(\n","        model=\"gpt-4o-mini\",\n","        messages=messages,\n","        max_tokens=800,\n","        temperature=0.5\n","    )\n","\n","    return response.choices[0].message.content\n"],"metadata":{"id":"ThQub_ycP6w0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(ask_gpt_with_context(\"what are the early signs of diabetic retinopathy?\"))\n"],"metadata":{"id":"Udj9r9laQjNT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["while True:\n","    q = input(\"You: \")\n","    if q.lower() in [\"exit\", \"quit\"]: break\n","    print(\"Bot:\", ask_gpt_with_context(q))\n"],"metadata":{"id":"ZsKHnPh4pFHv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from flask import Flask, request, jsonify\n","from flask_ngrok import run_with_ngrok\n","from flask_cors import CORS\n","\n","app = Flask(__name__)\n","CORS(app)  # Allows Live Server or any frontend to access the API\n","\n","run_with_ngrok(app)  # Automatically starts the public ngrok tunnel\n","\n","@app.route(\"/chat\", methods=[\"POST\"])\n","def chat():\n","    data = request.json\n","    user_input = data.get(\"message\", \"\")\n","\n","    try:\n","        # Assuming you have defined a context (or default to empty string)\n","        context = \"\"  # You can change this or manage stateful context if needed\n","        response = askgptwithcontext(context, user_input)\n","        return jsonify({\"response\": response})\n","\n","    except Exception as e:\n","        return jsonify({\"response\": f\"Error: {str(e)}\"})\n","\n","# Run the app\n","app.run(port=5001)\n"],"metadata":{"id":"gVeH8t5j19EJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install flask-ngrok flask\n"],"metadata":{"id":"2ymNctVrniaw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from flask import Flask, request, jsonify\n","from flask_ngrok import run_with_ngrok\n","\n","app = Flask(__name__)\n","run_with_ngrok(app)  # This exposes your Colab server via public URL\n","\n","@app.route(\"/generate\", methods=[\"POST\"])\n","def generate():\n","    data = request.get_json()\n","    user_input = data['messages'][-1]['content'] if data.get(\"messages\") else \"Hello\"\n","    result = model.predict(input=user_input)  # model = ConversationChain(...)\n","    return jsonify({\"reply\": result})\n","\n","app.run()\n"],"metadata":{"id":"61hTMvF-nkEV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install flask-ngrok flask"],"metadata":{"id":"pZiHZsOZnw2B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from flask import Flask, request, jsonify\n","from flask_ngrok import run_with_ngrok\n","\n","app = Flask(__name__)\n","run_with_ngrok(app)  # This exposes your Colab server via public URL\n","\n","@app.route(\"/generate\", methods=[\"POST\"])\n","def generate():\n","    data = request.get_json()\n","    user_input = data['messages'][-1]['content'] if data.get(\"messages\") else \"Hello\"\n","    result = model.predict(input=user_input)  # model = ConversationChain(...)\n","    return jsonify({\"reply\": result})\n","\n","app.run()"],"metadata":{"id":"Z1MxOrghnz_w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install flask-ngrok flask"],"metadata":{"id":"0ZIz36MmotJB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget -O ngrok.zip https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.zip\n","!unzip ngrok.zip\n"],"metadata":{"id":"yDBHXWmjqn0j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!./ngrok config add-authtoken 2vwWvqV9f0X1vC4kB5i1yvZtLd9_2W8Zppe7XRPP9wXs1ZCRi\n"],"metadata":{"id":"6tE2zovUp5ec"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from flask import Flask, request, jsonify\n","import threading\n","\n","app = Flask(__name__)\n","\n","@app.route(\"/\")\n","def home():\n","    return \"DR chatbot backend is up.\"\n","\n","@app.route(\"/generate\", methods=[\"POST\"])\n","def generate():\n","    data = request.get_json()\n","    msg = data.get(\"messages\", [{}])[-1].get(\"content\", \"\")\n","    return jsonify({\"reply\": f\"You said: {msg}\"})\n","\n","def run_app():\n","    app.run(port=5000)\n","\n","# Run Flask in the background\n","threading.Thread(target=run_app).start()\n"],"metadata":{"id":"ihYe_gpZoxZw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import subprocess\n","import time\n","import requests\n","\n","# Start ngrok in the background\n","subprocess.Popen([\"./ngrok\", \"http\", \"5000\"])\n","\n","# Wait a few seconds for ngrok to initialize\n","time.sleep(4)\n","\n","# Get the public URL from ngrok's API\n","try:\n","    tunnels = requests.get(\"http://localhost:4040/api/tunnels\").json()['tunnels']\n","    for tunnel in tunnels:\n","        print(\"Ngrok URL:\", tunnel['public_url'])\n","except Exception as e:\n","    print(\"Error:\", e)\n"],"metadata":{"id":"oXtLR812wUdL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Debugging\n"],"metadata":{"id":"GSrlZi6TzJw_"}},{"cell_type":"code","source":["!pip install flask flask-cors flask-ngrok"],"metadata":{"id":"XS_pTI2PzLMD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from flask import Flask, request, jsonify\n","from flask_cors import CORS\n","\n","app = Flask(__name__)\n","CORS(app)  # ‚úÖ This enables CORS for all origins (including Live Server)\n","\n","@app.route('/chat', methods=['POST'])\n","def chat():\n","    data = request.json\n","    user_message = data.get('message', '')\n","    response = f\"Echo: {user_message}\"  # Replace with real model output\n","    return jsonify({'response': response})\n","\n","# Start Flask in Colab using flask-ngrok\n","from flask_ngrok import run_with_ngrok\n","run_with_ngrok(app)\n","app.run()"],"metadata":{"id":"fjLkIzHezPjD"},"execution_count":null,"outputs":[]}]}